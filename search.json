[{"title":"xtrabackup备份","url":"/xtrabackup%E5%A4%87%E4%BB%BD.html","content":"简介Percona XtraBackup 是一款开源、免费的 MySQL 热备份软件，提供定时备份、增量备份等功能。\n前置准备系统: centos7.9\n已安装软件: mysql5.7\n安装percona 需要和 mysql 版本对应，此处使用 mysql5.7，需要安装 percona-xtrabackup-24\n安装仓库\n[root@localhost ~] yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n\n测试仓库\n[root@localhost ~] yum list | grep percona\n\n激活仓库\n[root@localhost ~] percona-release enable-only tools release\n\n安装\n[root@localhost ~] yum install percona-xtrabackup-24\n\n权限要求系统权限：需要系统账号有对应目录的读写权限，用来备份 mysql 文件，一般直接用 root 用户即可。\nmysql账号权限：\nmysql&gt; CREATE USER &#x27;bkpuser&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;As123456!&#x27;;mysql&gt; GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT ON *.* TO &#x27;bkpuser&#x27;@&#x27;%&#x27;;mysql&gt; FLUSH PRIVILEGES;\n\n备份此部分用来了解原理及基础的使用方法，如果想要直接使用的话，可以直接查看备份脚本部分\n全量备份开始备份[root@localhost ~] xtrabackup --backup --user=bkpuser --password=As123456! --target-dir=/data/backups/base...xtrabackup: Transaction log of lsn (26970807) to (137343534) was copied.160906 10:19:18 completed OK!\n\n\n–backup: 表示备份操作\n–user: mysql的用户名(即权限要求配置的 bkpuser)\n–password: mysql 的密码\n–target-dir: 备份文件存在的文件夹\n\n全量备份预处理由于数据是在不同的时间备份的，数据可能会被更改，所以在执行恢复前需要对数据预处理，执行：\n[root@localhost ~] xtrabackup --prepare --target-dir=/data/backups/base...InnoDB: Shutdown completed; log sequence number 2755624221021 16:59:23 completed OK!\n\n\n–prepare: 表示预处理操作\n–target-dir: 需要预处理数据的文件夹\n\n恢复备份恢复备份前必须先进行预处理，mysql 必须停止，并且 mysql 的 datadir 目录为空。\n# 关闭 mysql 服务[root@localhost ~] service mysqld stop# 删除 mysql 的 datadir，一定要谨慎，别删错了[root@localhost ~] rm -rf /var/lib/mysql/# 恢复备份文件，如果想要恢复备份后删除备份文件，可以将 `--copy-back` 替换为 `--move-back`(其实手动copy过去也可以, 不一定要通过 xtrabackup 命令)[root@localhost ~] xtrabackup --copy-back --target-dir=/data/backups/base# 由于 /var/lib/mysql/ 被删除了，所以这里需要给文件夹重新赋权限，如果开启了selinux, 也需要关闭, 不然会启动mysql失败。[root@localhost ~] chown -R mysql:mysql /var/lib/mysql/# 重新启动[root@localhost ~] service mysqld start\n\n增量备份增量备份的原理，是因为每个 InnoDB 页面都包含一个日志序列号 (LSN)。 LSN 是整个数据库的系统版本号。每个页面的 LSN 显示它最近的更改时间。\n创建增量备份全量备份的 target-dir 目录下会生成一个 xtrabackup_checkpoints 文件，里面包含的 to_lsn ，就是全量备份结束时的 LSN, 文件格式如下:\nbackup_type = full-preparedfrom_lsn = 0to_lsn = 2755117last_lsn = 2755126compact = 0recover_binlog_info = 0flushed_lsn = 2755126\n\n基于之前做的全量备份，我们可以使用如下命令做第一次增量备份\n[root@localhost ~] xtrabackup --backup --user=bkpuser --password=As123456! --target-dir=/data/backups/inc1 --incremental-basedir=/data/backups/base\n\n\n–target-dir: 此次增量备份保存数据的文件夹\n–incremental-basedir: 基于哪次备份的文件夹做增量备份\n\n查看第一次增量备份的 /data/backups/inc1/xtrabackup_checkpoints 文件,会发现from_lsn就是全量备份里面的 to_lsn\nbackup_type = incrementalfrom_lsn = 2755117to_lsn = 2755757last_lsn = 2755766compact = 0recover_binlog_info = 0flushed_lsn = 2755766\n\n如果想基于第一次增量备份的数据做第二次增量备份，使用以下命令\n[root@localhost ~] xtrabackup --backup --user=bkpuser --password=As123456! --target-dir=/data/backups/inc2 --incremental-basedir=/data/backups/inc1\n\n查看第二次增量备份的 /data/backups/inc1/xtrabackup_checkpoints 文件\nbackup_type = incrementalfrom_lsn = 2755757to_lsn = 2762910last_lsn = 2762919compact = 0recover_binlog_info = 0flushed_lsn = 2762919\n\n增量备份预处理增量备份的预处理方式与全量备份的不同。\n\n全量备份预处理会包含两个步骤，一是提交事务并且针对日志文件中的数据进行重放；二是未提交的事务进行回滚。\n\n增量备份预处理要跳过第二个步骤，因为未提交的事务可能会在下一个增量备份中提交，我们可以使用 --apply-log-only来避免日志回滚，如果没有使用此参数的话，后面的增量备份可能会无法使用。\n\n\n基于前面的操作，我们现在有这些备份文件\n/data/backups/base/data/backups/inc1/data/backups/inc2\n\n首先预处理之前的全量备份，但是要阻止日志回滚\n[root@localhost ~]# xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base...InnoDB: Shutdown completed; log sequence number 2755756InnoDB: Number of pools: 1221021 18:20:37 completed OK!\n\n接着预处理第一次增量备份，此时会把增量的数据添加到全量备份(/data/backups/base)中。此时使用 /data/backups/base 恢复备份会就是第一次增量备份时的数据。\n[root@localhost ~]# xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base --incremental-dir=/data/backups/inc1...InnoDB: Number of pools: 1xtrabackup: xtrabackup_logfile detected: size=8388608, start_lsn=(2755757)...221021 18:23:59 completed OK!\n\n增量备份不能预处理两次,即使用 --incremental-basedir 备份的数据，因为会重复执行sql\n\n接着预处理第二次增量备份，此时使用 /data/backups/base 恢复备份就是第二次增量备份时的数据\n[root@localhost ~]# xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base --incremental-dir=/data/backups/inc2...221021 18:24:45 completed OK!\n\n压缩mysql 数据量过大时会导致备份速度慢，这时可以使用压缩功能来加快备份时间\n前置准备压缩功能基于 qpress 工具实现的，且需要通过 percona-release 配置此工具\n[root@localhost ~]# percona-release enable tools[root@localhost ~]# yum install -y qpress\n\n压缩备份使用 --compress 即可实现压缩功能,备份后的文件都是以 qp 结尾的\n[root@localhost ~]# xtrabackup --backup --user=bkpuser --password=As123456! --compress --target-dir=/data/compressed/\n\n结合 --compress-threads 进行多线程压缩\n[root@localhost ~]# xtrabackup --backup --user=bkpuser --password=As123456! --compress --compress-threads=4 --target-dir=/data/compressed/...221024 11:00:11 [00] Compressing /data/compressed/backup-my.cnf.qp221024 11:00:11 [00]        ...done221024 11:00:11 [00] Compressing /data/compressed/xtrabackup_info.qp221024 11:00:11 [00]        ...donextrabackup: Transaction log of lsn (2756164) to (2756173) was copied.221024 11:00:12 completed OK!\n\n解压缩先使用 --decompress 解压缩文件，压缩后的文件没有 .qp 后缀。解压后默认不会删除压缩文件，如果要删除，可以使用 --remove-original 属性。即使不删除，使用 --copy-back 或 --move-back 也不会移动压缩文件。加压缩后与普通备份的文件一样，先预处理后恢复备份。\n[root@localhost ~]# xtrabackup --decompress --target-dir=/data/compressed/\n\n加密自行查看文档，本文不讨论，文档地址：https://docs.percona.com/percona-xtrabackup/2.4/backup_scenarios/encrypted_backup.html\n备份脚本为了简化上面的备份步骤，可以自行编辑 shell 脚本。下面提供一套每天定时备份,最多保留7天备份的脚本。\nST_percona_backup.sh此脚本可以在线热备份数据库，每天备份一次，如果一天运行多次，则只有第一次会生效，最多会生成1个全量备份和6个增量备份(可通过days配置)。配置在定时任务中，每天至少执行两次。\n执行示例: sh /percona/ST_percona_backup.sh\n#!/bin/bash#Script for SecureTransport - Online MySQL backup with Parcona XtraBackup#Created by Genata 2019#Make sure to have enough free space for backups.# my.cnf 配置文件的目录，FDH=/etc/my.cnf# xtrabackup 的执行目录hd=/usr/bin/# 日志文件ld=/percona/logs# 备份存放的文件夹bd=/percona/backup# 保存多少天的增量数据days=6# 多线程的线程数pp=4# mysql 的账号密码dbuser=bkpuserdbpass=As123456!hn=`uname -n`if [ ! -d &quot;$ld&quot; ]; then    mkdir -p $ldfiecho &quot;[`date -Iseconds`]&quot; Backup start... &gt;&gt;$ld/ST_percona_backup.logdate -Iseconds &gt;$ld/e_backup_percona#Get current date in format YYYY-MM-DD#Created directory structure is:# -YYYY-MM-DD#   |-full#   |-inc1#   |-inc2#   ...#   |-incN#where N=days configured. Set days=6 for weekly cycle.bp=`date +%F`if [ -d &quot;$bd/$bp&quot; ]; then  if [ -d &quot;$bd/$bp/full&quot; ]; then    echo &quot;[`date -Iseconds`]&quot; Full backup for today $bp already exist. Exiting. &gt;&gt;$ld/ST_percona_backup.log    echo &quot;[`date -Iseconds`]&quot; Backup done. &gt;&gt;$ld/ST_percona_backup.log    rm $ld/e_backup_percona 2&gt;/dev/null    exit 0  else    echo &quot;[`date -Iseconds`]&quot; Full backup for today do not exist. Removing $&#123;bp&#125;. &gt;&gt;$ld/ST_percona_backup.log    rm -r -f &quot;$bd/$bp&quot;    bp=&quot;&quot;  fielse  bp=&quot;&quot;fifor i in `seq 1 $days`; do  bp1=`date -d &quot;-$i day&quot; +%F`  if [ -d &quot;$bd/$bp1&quot; ]; then    bp=$bp1    bi=$i    break  fidoneif [ -z &quot;$bp&quot; ]; then  #Perform Full backup  bp=`date +%F`  echo &quot;[`date -Iseconds`]&quot; Will create full backup $bd/$bp/full &gt;&gt;$ld/ST_percona_backup.log  mkdir -p $bd/$bp  echo &quot;[`date -Iseconds`]&quot; Start full backup $bd/$bp/full &gt;&gt;$ld/ST_percona_xtrabackup.log  $&#123;hd&#125;xtrabackup --defaults-file=$FDH --backup --user=$dbuser --password=$dbpass --parallel=$pp --target-dir=$bd/$bp/full &gt;&gt;$ld/ST_percona_xtrabackup.log 2&gt;&amp;1  pxe=$?  if [ $pxe -eq 0 ]; then    echo &quot;[`date -Iseconds`]&quot; Backup created sucessfully. Hostname: $hn &gt;&gt;$ld/ST_percona_backup.log\techo $hn &gt;$bd/$bp/full/backup_hostname  else    rm -r -f &quot;$bd/$bp/full&quot;    echo &quot;[`date -Iseconds`]&quot; Error creating backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_backup.log  fielse  #Perform Incremental backup  if [ -d &quot;$bd/$bp/full&quot; ]; then    if [ -d &quot;$bd/$bp/inc$bi&quot; ]; then      echo &quot;[`date -Iseconds`]&quot; Incremental backup for today already exist. Exiting. &gt;&gt;$ld/ST_percona_backup.log      echo &quot;[`date -Iseconds`]&quot; Backup done. &gt;&gt;$ld/ST_percona_backup.log      rm $ld/e_backup_percona 2&gt;/dev/null      exit 0    else      if [ &quot;$bi&quot; -eq &quot;1&quot; ]; then        #Perform first incremental from full backup        echo &quot;[`date -Iseconds`]&quot; Will create incremental backup $bd/$bp/inc$bi from $bd/$bp/full &gt;&gt;$ld/ST_percona_backup.log        mkdir -p $bd/$bp/inc$bi        echo &quot;[`date -Iseconds`]&quot; Start incremental backup $bd/$bp/inc$bi from $bd/$bp/full &gt;&gt;$ld/ST_percona_xtrabackup.log        $&#123;hd&#125;xtrabackup --defaults-file=$FDH --backup --user=$dbuser --password=$dbpass --parallel=$pp --target-dir=$bd/$bp/inc$bi --incremental-basedir=$bd/$bp/full &gt;&gt;$ld/ST_percona_xtrabackup.log 2&gt;&amp;1        pxe=$?        if [ $pxe -eq 0 ]; then          echo &quot;[`date -Iseconds`]&quot; Backup created sucessfully. Hostname: $hn &gt;&gt;$ld/ST_percona_backup.log\t\t  echo $bd/$bp/inc$bi/backup_hostname        else          rm -r -f &quot;$bd/$bp/inc$bi&quot;          echo &quot;[`date -Iseconds`]&quot; Error creating backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_backup.log        fi      else        bi1=$((bi -1))        if [ -d &quot;$bd/$bp/inc$bi1&quot; ]; then          #Perform N -th incremental from N-1 -th backup          echo &quot;[`date -Iseconds`]&quot; Will create incremental backup $bd/$bp/inc$bi from $bd/$bp/inc$bi1 &gt;&gt;$ld/ST_percona_backup.log          mkdir -p $bd/$bp/inc$bi          echo &quot;[`date -Iseconds`]&quot; Start incremental backup $bd/$bp/inc$bi from $bd/$bp/inc$bi1 &gt;&gt;$ld/ST_percona_xtrabackup.log          $&#123;hd&#125;xtrabackup --defaults-file=$FDH --backup --user=$dbuser --password=$dbpass --parallel=$pp --target-dir=$bd/$bp/inc$bi --incremental-basedir=$bd/$bp/inc$bi1 &gt;&gt;$ld/ST_percona_xtrabackup.log 2&gt;&amp;1          pxe=$?          if [ $pxe -eq 0 ]; then            echo &quot;[`date -Iseconds`]&quot; Backup created sucessfully. Hostname: $hn &gt;&gt;$ld/ST_percona_backup.log\t\t\techo $bd/$bp/inc$bi/backup_hostname          else            rm -r -f &quot;$bd/$bp/inc$bi&quot;            echo &quot;[`date -Iseconds`]&quot; Error creating backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_backup.log          fi        else          #Searching for previous backup.          echo &quot;[`date -Iseconds`]&quot; Incremental backup &quot;$bd/$bp/inc$bi1&quot; do not exist. Searching for previous backup. &gt;&gt;$ld/ST_percona_backup.log          bd1=`ls -1trd $bd/$bp/inc* 2&gt;/dev/null | tail -1`          if [ -z &quot;$bd1&quot; ]; then            #Perform first incremental from full backup            echo &quot;[`date -Iseconds`]&quot; Will create incremental backup $bd/$bp/inc$bi from $bd/$bp/full &gt;&gt;$ld/ST_percona_backup.log            mkdir -p $bd/$bp/inc$bi            echo &quot;[`date -Iseconds`]&quot; Start incremental backup $bd/$bp/inc$bi from $bd/$bp/full &gt;&gt;$ld/ST_percona_xtrabackup.log            $&#123;hd&#125;xtrabackup --defaults-file=$FDH --backup --user=$dbuser --password=$dbpass --parallel=$pp --target-dir=$bd/$bp/inc$bi --incremental-basedir=$bd/$bp/full &gt;&gt;$ld/ST_percona_xtrabackup.log 2&gt;&amp;1            pxe=$?            if [ $pxe -eq 0 ]; then              echo &quot;[`date -Iseconds`]&quot; Backup created sucessfully. Hostname: $hn &gt;&gt;$ld/ST_percona_backup.log\t\t\t  echo $bd/$bp/inc$bi/backup_hostname            else              rm -r -f &quot;$bd/$bp/inc$bi&quot;              echo &quot;[`date -Iseconds`]&quot; Error creating backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_backup.log            fi          else            #Perform N -th incremental from N-1 -th backup            echo &quot;[`date -Iseconds`]&quot; Will create incremental backup $bd/$bp/inc$bi from $bd1 &gt;&gt;$ld/ST_percona_backup.log            mkdir -p $bd/$bp/inc$bi            echo &quot;[`date -Iseconds`]&quot; Start incremental backup $bd/$bp/inc$bi from $bd1 &gt;&gt;$ld/ST_percona_xtrabackup.log            $&#123;hd&#125;xtrabackup --defaults-file=$FDH --backup --user=$dbuser --password=$dbpass --parallel=$pp --target-dir=$bd/$bp/inc$bi --incremental-basedir=$bd1 &gt;&gt;$ld/ST_percona_xtrabackup.log 2&gt;&amp;1            pxe=$?            if [ $pxe -eq 0 ]; then              echo &quot;[`date -Iseconds`]&quot; Backup created sucessfully. Hostname: $hn &gt;&gt;$ld/ST_percona_backup.log\t\t\t  echo $bd/$bp/inc$bi/backup_hostname            else              rm -r -f &quot;$bd/$bp/inc$bi&quot;              echo &quot;[`date -Iseconds`]&quot; Error creating backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_backup.log            fi          fi        fi      fi    fi  else    echo &quot;[`date -Iseconds`]&quot; Full backup for $bp do not exist. Removing $&#123;bp&#125;. Please run this script again. Exiting. &gt;&gt;$ld/ST_percona_backup.log    rm -r -f &quot;$bd/$bp&quot;    echo &quot;[`date -Iseconds`]&quot; Backup done. &gt;&gt;$ld/_ST_percona_backup.log    rm $ld/e_backup_percona 2&gt;/dev/null    exit 2  fifiecho &quot;[`date -Iseconds`]&quot; Backup done. &gt;&gt;$ld/ST_percona_backup.logrm $ld/e_backup_percona 2&gt;/dev/nullexit $pxe\n\nST_percona_prepare.sh此脚本是针对上面的备份文件做预处理的。此脚本包含一个日期参数用来指定恢复哪一天的备份数据。它会根据指定的日期自动的合并全量备份和增量备份，预处理后的文件默认存放在 $bd/prep 文件夹中。 此脚本比较耗时，可以每天定时执行，也可以在需要恢复数据前再手动执行。\n执行示例: sh /percona/ST_percona_prepare.sh 2022-10-24\n#!/bin/bash#Script for SecureTransport - Prepare online MySQL backup for restore with Parcona XtraBackup#Created by Genata 2019#Prepare can be done on another machine as long as script has full access to backups.#Note that prepare always use a copy of original directories. Make sure to have enough free space for prepare. if [ -z &quot;$1&quot; ]; then  echo &quot;Usage: $(basename $0) &lt;Restore date&gt;&quot;  exit 1fi# xtrabackup 文件目录hd=/usr/bin/# 日志目录ld=/percona/logs# 备份的文件夹目录bd=/percona/backup# 增量备份的天数days=6# 多线程数量pp=4#The next value is used instead of buffer_pool_size. Recomended to use 1G or 2G or 4G based on the available memory. um=1Grd=`date -d &quot;$1&quot; +%F 2&gt;/dev/null`cr=$?if [ &quot;$cr&quot; -gt 0 ]; then  echo Invalid restore date  exit $crfibp=$rdif [ -d &quot;$bd/$bp&quot; ]; then  echo Prepare full backup from $bp  echo &quot;[`date -Iseconds`]&quot; Prepare full backup start... &gt;&gt;$ld/ST_percona_prepare.log  rm -r -f &quot;$bd/prep&quot;  rm &quot;$bd/prep_date&quot; 2&gt;/dev/null  cp -r &quot;$bd/$bp/full&quot; &quot;$bd/prep&quot;  echo $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prepare.log  $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prep_xtrabackup.log 2&gt;&amp;1  pxe=$?  if [ $pxe -eq 0 ]; then    echo $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prepare.log    $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prep_xtrabackup.log 2&gt;&amp;1    pxe=$?    if [ $pxe -eq 0 ]; then      echo Full backup $rd prepared sucessfully.      echo &quot;[`date -Iseconds`]&quot; Full backup $rd prepared sucessfully. &gt;&gt;$ld/ST_percona_prepare.log      echo $rd &gt; &quot;$bd/prep_date&quot;    else      rm -r -f &quot;$bd/prep&quot;      rm &quot;$bd/prep_date&quot; 2&gt;/dev/null      echo Error preparing full backup. xtrabackup exit code: $pxe      echo &quot;[`date -Iseconds`]&quot; Error preparing full backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_prepare.log    fi  else    rm -r -f &quot;$bd/prep&quot;    rm &quot;$bd/prep_date&quot; 2&gt;/dev/null    echo Error preparing full backup. xtrabackup exit code: $pxe    echo &quot;[`date -Iseconds`]&quot; Error preparing full backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_prepare.log  fi  echo &quot;[`date -Iseconds`]&quot; Prepare full backup done. &gt;&gt;$ld/ST_percona_prepare.log  exit $pxeelse  bp=&quot;&quot;fifor i in `seq 1 $days`; do  bp1=`date -d &quot;$rd -$i day&quot; +%F`  if [ -d &quot;$bd/$bp1&quot; ]; then    bp=$bp1    bi=$i    break  fidoneif [ -z &quot;$bp&quot; ]; then  echo Could not find backup from $rd  echo &quot;[`date -Iseconds`]&quot; Could not find backup from $rd &gt;&gt;$ld/ST_percona_prepare.log  exit 2else  if [ -d &quot;$bd/$bp/inc$bi&quot; ]; then    if [ -d &quot;$bd/$bp/full&quot; ]; then      echo Prepare full backup from $bp and inc $bi      echo &quot;[`date -Iseconds`]&quot; Prepare incremental backup start... &gt;&gt;$ld/ST_percona_prepare.log      rm -r -f &quot;$bd/prep&quot;      rm &quot;$bd/prep_date&quot; 2&gt;/dev/null      cp -r &quot;$bd/$bp/full&quot; &quot;$bd/prep&quot;      echo $&#123;hd&#125;xtrabackup --prepare --apply-log-only --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prepare.log      $&#123;hd&#125;xtrabackup --prepare --apply-log-only --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prep_xtrabackup.log 2&gt;&amp;1      pxe=$?      if [ $pxe -eq 0 ]; then        echo &quot;[`date -Iseconds`]&quot; Incremental backup step full prepared sucessfully. &gt;&gt;$ld/ST_percona_prepare.log      else        rm -r -f &quot;$bd/prep&quot;        rm &quot;$bd/prep_date&quot; 2&gt;/dev/null        echo Error preparing incremental backup step full. xtrabackup exit code: $pxe        echo &quot;[`date -Iseconds`]&quot; Error preparing incremental backup step full. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_prepare.log        echo &quot;[`date -Iseconds`]&quot; Prepare incremental backup done. &gt;&gt;$ld/ST_percona_prepare.log        exit $pxe      fi      if [ &quot;$bi&quot; -gt &quot;1&quot; ]; then        for i in `seq 1 $((bi-1))`; do          if [ -d &quot;$bd/$bp/inc$i&quot; ]; then            rm -r -f &quot;$bd/inc&quot; 2&gt;/dev/null            cp -r &quot;$bd/$bp/inc$i&quot; &quot;$bd/inc&quot;            echo $&#123;hd&#125;xtrabackup --prepare --apply-log-only --use-memory=$um --target-dir=&quot;$bd/prep&quot; --incremental-dir=$bd/inc \\#$bp/inc$i &gt;&gt;$ld/ST_percona_prepare.log            $&#123;hd&#125;xtrabackup --prepare --apply-log-only --use-memory=$um --target-dir=&quot;$bd/prep&quot; --incremental-dir=$bd/inc &gt;&gt;$ld/ST_percona_prep_xtrabackup.log 2&gt;&amp;1            pxe=$?            if [ $pxe -eq 0 ]; then              echo Incremental backup step inc$i prepared sucessfully.              echo &quot;[`date -Iseconds`]&quot; Incremental backup step inc$i prepared sucessfully. &gt;&gt;$ld/ST_percona_prepare.log            else              rm -r -f &quot;$bd/prep&quot;              rm &quot;$bd/prep_date&quot; 2&gt;/dev/null              rm -r -f &quot;$bd/inc&quot;              echo Error preparing incremental backup step inc$i. xtrabackup exit code: $pxe              echo &quot;[`date -Iseconds`]&quot; Error preparing incremental backup step inc$i. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_prepare.log              echo &quot;[`date -Iseconds`]&quot; Prepare incremental backup done. &gt;&gt;$ld/ST_percona_prepare.log              exit $pxe            fi          fi        done      fi      rm -r -f &quot;$bd/inc&quot; 2&gt;/dev/null      cp -r &quot;$bd/$bp/inc$bi&quot; &quot;$bd/inc&quot;      echo $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; --incremental-dir=$bd/inc \\#$bp/inc$bi &gt;&gt;$ld/ST_percona_prepare.log      $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; --incremental-dir=$bd/inc &gt;&gt;$ld/ST_percona_prep_xtrabackup.log 2&gt;&amp;1      pxe=$?      if [ $pxe -eq 0 ]; then        echo Incremental backup step inc$bi prepared sucessfully.        echo &quot;[`date -Iseconds`]&quot; Incremental backup step inc$bi prepared sucessfully. &gt;&gt;$ld/ST_percona_prepare.log        rm -r -f &quot;$bd/inc&quot;      else        rm -r -f &quot;$bd/prep&quot;        rm &quot;$bd/prep_date&quot; 2&gt;/dev/null        rm -r -f &quot;$bd/inc&quot;        echo Error preparing incremental backup step inc$bi. xtrabackup exit code: $pxe        echo &quot;[`date -Iseconds`]&quot; Error preparing incremental backup step inc$bi. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_prepare.log        echo &quot;[`date -Iseconds`]&quot; Prepare incremental backup done. &gt;&gt;$ld/ST_percona_prepare.log        exit $pxe      fi      echo All increments were merged sucessfully.      echo &quot;[`date -Iseconds`]&quot; All increments were merged sucessfully. &gt;&gt;$ld/ST_percona_prepare.log      echo $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prepare.log      $&#123;hd&#125;xtrabackup --prepare --use-memory=$um --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_prep_xtrabackup.log 2&gt;&amp;1      pxe=$?      if [ $pxe -eq 0 ]; then        echo Incremental backup $rd prepared sucessfully.        echo &quot;[`date -Iseconds`]&quot; Incremental backup $rd prepared sucessfully. &gt;&gt;$ld/ST_percona_prepare.log        echo $rd &gt; &quot;$bd/prep_date&quot;      else        rm -r -f &quot;$bd/prep&quot;        rm &quot;$bd/prep_date&quot; 2&gt;/dev/null        echo Error preparing incremental backup. xtrabackup exit code: $pxe        echo &quot;[`date -Iseconds`]&quot; Error preparing incremental backup. xtrabackup exit code: $pxe &gt;&gt;$ld/ST_percona_prepare.log      fi      echo &quot;[`date -Iseconds`]&quot; Prepare incremental backup done. &gt;&gt;$ld/ST_percona_prepare.log      exit $pxe    else      echo Could not find full backup in $bp      echo &quot;[`date -Iseconds`]&quot; Could not find full backup in $bp &gt;&gt;$ld/ST_percona_prepare.log      exit 2    fi  else    echo Could not find backup from $rd    echo &quot;[`date -Iseconds`]&quot; Could not find backup from $rd &gt;&gt;$ld/ST_percona_prepare.log    exit 2  fifiexit 0\n\nST_percona_restore.sh恢复脚本，此脚本的功能是删除mysql的datadir目录，并将上一步预处理后的文件($bd/prep目录)复制到mysql的datadir目录，如果恢复失败，则会使用之前创建的备份恢复原数据库。此脚本不会在恢复数据完成后重新启动mysql服务，需要手动启动。mysql的datadir目录的文件夹权限可能也需要重新配置。\n#!/bin/bash#Script for SecureTransport - Restore online MySQL backup with Parcona XtraBackup#Created by Genata 2019# my.cnf 配置文件FDH=/etc/my.cnf# xtrabackup 执行文件目录hd=/usr/bin/# 日志文件地址ld=/percona/logs# 备份文件目录bd=/percona/backupmdd=`cat &quot;$FDH&quot; |grep datadir | cut -d &quot;=&quot; -f2`bmd=mysql_`date +%F`if [ ! -d &quot;$bd/prep&quot; ]; then  echo Backup ready for restore does not exist. Please use percona_prepare.sh first.  exit 1fipb=`cat $bd/prep_date 2&gt;/dev/null`if [ -z &quot;$pb&quot; ]; then  echo Prepared backup could not be determined. Please use percona_prepare.sh first.  exit 2fiif [ -d &quot;$bd/$bmd&quot; ]; then  while true; do    read -p &quot;Backup directory $bd/$bmd exist and will be overwritten. Do you want to continue? [y/N]&quot; yn    case $yn in      [Yy]* ) rm -r -f $bd/$bmd 2&gt;/dev/null; break;;      [Nn]* ) exit;;      * ) exit;;    esac  donefihn=`uname -n`bhn=`cat $bd/prep/backup_hostname 2&gt;/dev/null`if [ &quot;$hn&quot; != &quot;$bhn&quot; ]; then  while true; do    read -p &quot;Hostname of the current machine \\&quot;$hn\\&quot; differ from the hostname of the machine where backup was created \\&quot;$bhn\\&quot;. In a Cluster environment create a backup for each node separately and upon restore make sure you are restoring it on the same server. Some configuration options are node specific and database contains node ID in a table ConfigurationOption. If you restore database on a wrong node ST will start but will not find specific options for current node and will not work properly.Do you want to continue? [y/N]&quot; yn    case $yn in      [Yy]* ) break;;      [Nn]* ) exit;;      * ) exit;;    esac  donefiecho Restore start... echo &quot;[`date -Iseconds`]&quot; Restore start... &gt;&gt;$ld/ST_percona_restore.logmpid=`ps -ef | grep mysql | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | tr &quot;\\n&quot; &quot; &quot;`if [ ! -z &quot;$mpid&quot; ]; then  $FDH/bin/stop_allfimpid=`ps -ef | grep mysql | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | tr &quot;\\n&quot; &quot; &quot;`if [ ! -z &quot;$mpid&quot; ]; then  echo kill -9 $mpidficp -r $mdd $bd/$bmdecho Backup of $mdd to $bd/$bmd finished.echo &quot;[`date -Iseconds`]&quot; Backup of $mdd to $bd/$bmd finished. &gt;&gt;$ld/ST_percona_restore.logrm -r -f $mddmkdir -p $mdd$&#123;hd&#125;xtrabackup --defaults-file=$FDH --copy-back --target-dir=&quot;$bd/prep&quot; &gt;&gt;$ld/ST_percona_restore_xtrabackup.log 2&gt;&amp;1pxe=$?if [ $pxe -eq 0 ]; then  echo Restore of backup from $pb finished successfully.  echo &quot;[`date -Iseconds`]&quot; Restore of backup from $pb finished successfully. &gt;&gt;$ld/ST_percona_restore.logelse  echo Error restoring backup from $pb. xtrabackup exit code: $pxe. Rollback to previous version of database from $bd/$bmd ...  echo &quot;[`date -Iseconds`]&quot; Error restoring backup from $pb. xtrabackup exit code: $pxe. Rollback to previous version of database from $bd/$bmd ... &gt;&gt;$ld/ST_percona_restore.log  rm -r -f $mdd  mkdir -p $mdd  cp -r $bd/$bmd/* $mddfiecho Restore done.echo &quot;[`date -Iseconds`]&quot; Restore done. &gt;&gt;$ld/ST_percona_restore.logexit 0\n\n参考链接官方文档(支持mysql5.7及以下): https://docs.percona.com/percona-xtrabackup/2.4/index.html\n备份脚本参考: https://support.axway.com/kb/180269/language/en\n","categories":["linux"],"tags":["mysql"]},{"title":"springboot国际化","url":"/springboot%E5%9B%BD%E9%99%85%E5%8C%96.html","content":"简介springboot 默认支持了国际化, 自动注入 MessageSource 到容器中, 通过 getMessage 方法可以读取 messages.properties 中的数据.\n前置准备jdk: 1.8\nspringboot: 2.3.2.RELEASE\n简单使用MessageSource读取国际化的 bean, springboot 默认已配置，可直接注入使用。\n@Resourceprivate MessageSource messageSource;\n\n资源文件存放国际化翻译的文件，使用 spring.messages.basename 指定读取的资源文件名，默认值 messages, 通过 _语言标识 来对应不同语言。\n下面是测试使用的资源文件：\n默认 messages.properties\ntest=测试noUser=用户[&#123;0&#125;]不存在。common=通用\n\n简体中文(中国大陆) messages_zh_CN.properties\ntest=测试noUser=用户[&#123;0&#125;]不存在。\n\n繁体中文(中国台湾) messages_zh_TW.properties\ntest=測試noUser=用戶[&#123;0&#125;]不存在。\n\n英语(美国) messages_en_US.properties\ntest=testnoUser=user [&#123;0&#125;] not exists.\n\n使用无占位符\n// 结果: testmessageSource.getMessage(&quot;test&quot;, null, new Locale(&quot;en&quot;, &quot;US&quot;));\n\n有占位符\n// 结果: 用户[张三]不存在。messageSource.getMessage(&quot;noUser&quot;, new Object[]&#123;&quot;张三&quot;&#125;, new Locale(&quot;zh&quot;, &quot;CN&quot;));\n\n读取默认文件\n// 结果: 通用messageSource.getMessage(&quot;common&quot;, null, new Locale(&quot;en&quot;, &quot;US&quot;));\n\n默认值\n// 结果: 默认值messageSource.getMessage(&quot;apple&quot;, null, &quot;默认值&quot;, new Locale(&quot;en&quot;, &quot;US&quot;));\n\nweb环境下使用web环境下一般是用户自己手动指定的语言环境(下文使用 Locale 代替)，我们可以通过用户的请求参数自动来获取 Locale. 省去每次手动选择  Locale 这个步骤\nLocaleResolverLocaleResolver 接口的作用是通过 resolveLocale 方法解析 request 请求获取用户的 Locale、然后存放到 LocaleContextHolder 中，LocaleContextHolder是使用 ThreadLocal 保存 Locale的，所以不同请求之间不会发生冲突。\n下面的例子中的 ParamLocaleResolver 是用来通过解析 url 链接上的 lang 字段来作为 Locale, 可以自行扩展，使用 header、cookie 等方式获取\nimport org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.util.StringUtils;import org.springframework.web.servlet.LocaleResolver;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.util.Locale;@Configurationpublic class I18nConfig &#123;    @Bean    public LocaleResolver localeResolver()&#123;        return new ParamLocaleResolver();    &#125;    /**     * 读取请求参数的国际化解析器     */    private static class ParamLocaleResolver implements LocaleResolver &#123;        /**         * 国际化的请求参数         */        private static final String PARAM = &quot;lang&quot;;        @Override        public Locale resolveLocale(HttpServletRequest request) &#123;            String l = request.getParameter(PARAM);            Locale locale = Locale.getDefault();            if(!StringUtils.isEmpty(l))&#123;                String[] split = l.split(&quot;_&quot;);                if(split.length != 2)&#123;                    throw new RuntimeException(&quot;语言格式错误&quot;);                &#125;                locale = new Locale(split[0], split[1]);            &#125;            return locale;        &#125;        @Override        public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123;        &#125;    &#125;&#125;\n\nI18nUtils国际化工具类，只是用来简化 MessageSource 的操作，用 MessageSource 效果一样。\nimport org.springframework.context.MessageSource;import org.springframework.context.i18n.LocaleContextHolder;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.util.Locale;@Componentpublic class I18nUtils &#123;    @Resource    private MessageSource messageSource;    /**     * 读取无参, 无默认值的     * @param code     * @return     */    public String getMessage(String code)&#123;        return messageSource.getMessage(code, null, LocaleContextHolder.getLocale());    &#125;    /**     * 读取无参, 无默认值的, 手动指定语言     * @param code     * @return     */    public String getMessage(String code, Locale locale)&#123;        return messageSource.getMessage(code, null, locale);    &#125;    /**     * 读取无参, 有默认值的     * @param code     * @return     */    public String getMessage(String code, String defaultValue)&#123;        return messageSource.getMessage(code, null, defaultValue, LocaleContextHolder.getLocale());    &#125;    /**     * 读取无参, 有默认值的, 手动指定语言     * @param code     * @return     */    public String getMessage(String code, String defaultValue, Locale locale)&#123;        return messageSource.getMessage(code, null, defaultValue, locale);    &#125;    /**     * 读取有参, 无默认值的     * @param code     * @return     */    public String getMessage(String code, Object[] args)&#123;        return messageSource.getMessage(code, args, LocaleContextHolder.getLocale());    &#125;    /**     * 读取有参, 无默认值的, 手动指定语言     * @param code     * @return     */    public String getMessage(String code, Object[] args, Locale locale)&#123;        return messageSource.getMessage(code, args, locale);    &#125;    /**     * 读取有参，有默认值的     * @param code     * @return     */    public String getMessage(String code, Object[] args, String defaultValue)&#123;        return messageSource.getMessage(code, args, defaultValue, LocaleContextHolder.getLocale());    &#125;    /**     * 读取有参，有默认值的, 手动指定语言     * @param code     * @return     */    public String getMessage(String code, Object[] args, String defaultValue, Locale locale)&#123;        return messageSource.getMessage(code, args, defaultValue, locale);    &#125;&#125;\n\n使用注入工具类\n@Resourceprivate I18nUtils i18nUtils;\n\n无占位符\n// 结果: testi18nUtils.getMessage(&quot;test&quot;);\n\n有占位符\n// 结果: 用户[张三]不存在。i18nUtils.getMessage(&quot;noUser&quot;, new Object[]&#123;&quot;张三&quot;&#125;);\n\n读取默认文件\n// 结果: 通用i18nUtils.getMessage(&quot;common&quot;);\n\n默认值\n// 结果: 默认值i18nUtils.getMessage(&quot;apple&quot;, &quot;默认值&quot;);\n\n参考链接官方文档: https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#context-functionality-messagesource\nbaeldung: https://www.baeldung.com/spring-boot-internationalization\n","categories":["java"],"tags":["springboot"]},{"title":"centos安装docker","url":"/centos%E5%AE%89%E8%A3%85docker.html","content":"前置准备系统：centos7.9\nyum安装卸载旧版本[root@localhost ~]# yum remove docker \\                  docker-client \\                  docker-client-latest \\                  docker-common \\                  docker-latest \\                  docker-latest-logrotate \\                  docker-logrotate \\                  docker-engine\n\n设置yum仓库安装 yum-utils 软件包（提供yum-config-manager实用程序）并设置稳定的存储库。我们这里使用阿里的存储库。官方的存储库需要外网，速度慢。\n[root@localhost ~]# yum install -y yum-utils[root@localhost ~]# yum-config-manager \\    --add-repo \\    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n安装安装最新版本[root@localhost ~]# yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\n\n安装指定版本\n列出要安装特定版本的Docker Engine：\n\n[root@localhost ~]# yum list docker-ce --showduplicates | sort -rdocker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stabledocker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stabledocker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stabledocker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable\n\n\n选择安装\n\n通过其完全合格的软件包名称安装特定版本，该软件包名称是软件包名称（docker-ce）加上版本字符串（第二列），从第一个冒号（:)开始，直至第一个连字符，并用连字符（-）分隔）。例如 docker-ce-18.09.1 。\n[root@localhost ~]# yum install docker-ce-18.09.1 docker-ce-cli-18.09.1 containerd.io docker-compose-plugin -y\n\n服务管理启动\n[root@localhost ~]# service docker start\n\n停止\n[root@localhost ~]# service docker stop\n\n重启\n[root@localhost ~]# service docker restart\n\n卸载卸载 Docker Engine，CLI 和 Containerd 软件包\n[root@localhost ~]# yum remove docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\n主机上的映像，容器，卷或自定义配置文件不会自动删除。要删除所有图像，容器和卷\n[root@localhost ~]# rm -rf /var/lib/docker[root@localhost ~]# rm -rf /var/lib/containerd\n\n参考链接官方文档：https://docs.docker.com/engine/install/centos/\n","categories":["linux"],"tags":["centos","docker"]},{"title":"nginx平滑升级","url":"/nginx%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7.html","content":"概述本文主要介绍如何在 nginx 运行中，不停止服务的情况下升级 nginx 的版本\n前置准备系统环境：centos7.9\n已安装软件：nginx-1.18.0(yum安装)\nnginx信号控制nginx 能够通过信号来进行控制，使用 kill -信号 master进程pid  。master进程pid 可以使用命令 ps axw -o pid,ppid,user,%cpu,vsz,wchan,command | egrep &#39;(nginx|PID)&#39; 获取，或者查看 nginx.pid  文件内容获取。\n\n\n\n信号\n说明\n\n\n\nTERM, INT\n强制退出 master 进程和 work 进程，直接丢弃未完成的请求\n\n\nQUIT\n平滑退出 master 进程和 work 进程，处理完已接收的请求，不接收新请求\n\n\nHUP\n重新读取配置文件，开启新 work 进程，平滑的关闭旧 work 进程\n\n\nUSR1\n开启新的日志文件\n\n\nUSR2\n升级 nginx 可执行文件\n\n\nWINCH\n平滑的退出 work 进程，配合 USR2 实现平滑升级\n\n\nwork 进程也可以使用信号控制，本文不做介绍，自行查看官方文档\n\n平滑升级步骤平滑升级\n首先把旧的 nginx（yum安装的是 /usr/sbin/nginx）执行文件进行备份，改名为 nginx-1.18.0.bak。\n将新版本的 nginx 解压编译，并将其中 objs/nginx 代替旧的 nginx 文件。\n向旧的 master 进程发送 USR2 信号，nginx 将会创建新的 master 进程和新的 worker 进程。\n向旧的 master 进程发送 WINCH 信号，停止旧的 worker 进程。\n如果升级成功，向旧的 master 进程发送 QUIT 信号，停止旧的 master 进程；如果升级失败，请参照下面步骤执行回滚操作。\n\n回滚\n向旧的 master 进程发送 HUP 信号，重新开启旧的 worker 进程。\n向新的 master 进程发送 QUIT 信号, 停止新的 master 进程。\n\n开始升级本文是将 yum 安装的 nginx-1.18.0 升级为 nginx-1.22.0\n下载源码包下载地址：https://nginx.org/en/download.html\n编译可执行文件创建 /usr/local/server 文件夹，然后上传下载的源码包到此目录。\n[root@localhost ~]# mkdir -p /usr/local/server\n\n查看旧 nginx 的配置参数\n\n编译\n[root@localhost ~]# cd /usr/local/server[root@localhost server]# tar zxvf nginx-1.22.0.tar.gz[root@localhost server]# cd nginx-1.22.0# 使用与旧 nginx 相同的配置[root@localhost nginx-1.22.0]# ./configure --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&#x27;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC&#x27; --with-ld-opt=&#x27;-Wl,-z,relro -Wl,-z,now -pie&#x27;# 编译，千万不要执行 make install, 否则配置文件等都会被覆盖[root@localhost nginx-1.22.0]# make\n\n如果编译中出现 C compiler cc is not found 错误信息，需要安装c++,  运行 yum install gcc 如果编译中出现 PCRE 错误信息，运行 yum install pcre-devel如果编译中出现 openssl 错误信息，运行 yum install openssl openssl-devel\n\n替换可执行文件# 先备份旧的[root@localhost nginx-1.22.0]# mv /usr/sbin/nginx /usr/sbin/nginx-1.18.0.bak# 替换[root@localhost nginx-1.22.0]# cp objs/nginx /usr/sbin/nginx\n\n开始平滑升级查看旧 master 进程的 pid,可以看到是 9927\n[root@localhost nginx-1.22.0]# ps axw -o pid,ppid,user,%cpu,vsz,wchan,command | egrep &#x27;(nginx|PID)&#x27;  PID  PPID USER     %CPU    VSZ WCHAN  COMMAND 9927     1 root      0.0  46464 sigsus nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf 9928  9927 nginx     0.0  46856 ep_pol nginx: worker process16746  9799 root      0.0 112812 -      grep -E --color=auto (nginx|PID)\n\n发送 USR2 信号, 生成了新的 master 进程，pid 是 16747， 且父进程是旧 master 进程。\n[root@localhost nginx-1.22.0]# kill -USR2 9927[root@localhost nginx-1.22.0]# ps axw -o pid,ppid,user,%cpu,vsz,wchan,command | egrep &#x27;(nginx|PID)&#x27;  PID  PPID USER     %CPU    VSZ WCHAN  COMMAND 9927     1 root      0.0  46464 sigsus nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf 9928  9927 nginx     0.0  46856 ep_pol nginx: worker process16747  9927 root      0.0  46516 sigsus nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf16748 16747 nginx     0.0  46916 ep_pol nginx: worker process16750  9799 root      0.0 112816 pipe_w grep -E --color=auto (nginx|PID)\n\n发送 WINCH 信号,  可以看到旧 master 进程 的 work 进程 9928 已经关闭了\n[root@localhost nginx-1.22.0]# kill -WINCH 9927[root@localhost nginx-1.22.0]# ps axw -o pid,ppid,user,%cpu,vsz,wchan,command | egrep &#x27;(nginx|PID)&#x27;  PID  PPID USER     %CPU    VSZ WCHAN  COMMAND 9927     1 root      0.0  46464 sigsus nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf16747  9927 root      0.0  46516 sigsus nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf16748 16747 nginx     0.0  46916 ep_pol nginx: worker process16777 16759 root      0.0 112812 -      grep -E --color=auto (nginx|PID)\n\n验证升级是否成功\n通过 curl 访问 nginx 的 index.html 页面(或者浏览器的控制台查看)，可以看到 Server 显示为 nginx/1.22.0，表示升级成功\n[root@localhost nginx-1.22.0]# curl -i 127.0.0.1HTTP/1.1 200 OKServer: nginx/1.22.0Date: Wed, 09 Mar 2022 11:16:43 GMTContent-Type: text/htmlContent-Length: 612Last-Modified: Thu, 29 Oct 2020 15:25:17 GMTConnection: keep-aliveETag: &quot;5f9adedd-264&quot;Accept-Ranges: bytes&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;    body &#123;        width: 35em;        margin: 0 auto;        font-family: Tahoma, Verdana, Arial, sans-serif;    &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\n\n成功后关闭旧的 master 进程\n[root@localhost nginx-1.22.0]# kill -QUIT 9927[root@localhost nginx-1.22.0]# ps axw -o pid,ppid,user,%cpu,vsz,wchan,command | egrep &#x27;(nginx|PID)&#x27;  PID  PPID USER     %CPU    VSZ WCHAN  COMMAND16747     1 root      0.0  46516 sigsus nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf16748 16747 nginx     0.0  46916 ep_pol nginx: worker process16833 16759 root      0.0 112812 -      grep -E --color=auto (nginx|PID)\n\n参考链接官方文档：https://nginx.org/en/docs/control.html#upgrade\nnginx平滑升级：https://www.361shipin.com/blog/1534406139729412096#nginx_68\n","categories":["linux"],"tags":["nginx"]},{"title":"nginx日志按天保存","url":"/nginx%E6%97%A5%E5%BF%97%E6%8C%89%E5%A4%A9%E4%BF%9D%E5%AD%98.html","content":"概述nginx 默认的日志文件是存放在单个日志文件中的，时间久了文件会很大，不利于分析日志。本文通过定时脚本的方式，实现按天来生成 nginx 日志。\n前置准备系统：centos7.9\n已安装软件：nginx1.22.0\n分隔日志创建定时脚本 /var/log/nginx/cutnginxlog.sh ，内容如下\n#!/bin/sh# nginx日志路径 LOGS_PATH=/var/log/nginx/TODAY=$(date +%Y%m%d) # 移动日志并改名# error.log 一般很小，没必要按日期切割，可自行选择是否开启# mv $&#123;LOGS_PATH&#125;/error.log $&#123;LOGS_PATH&#125;/error$&#123;TODAY&#125;.logmv $&#123;LOGS_PATH&#125;/access.log $&#123;LOGS_PATH&#125;/access$&#123;TODAY&#125;.log # 向nginx主进程发送重新打开日志文件的信号，命令解释请查看参考链接里的官方文档地址kill -USR1 $(cat /var/run/nginx.pid)\n\n允许所有用户执行此脚本\n[root@localhost ~]# chmod a+x cutnginxlog.sh\n\n创建定时任务，每天 23:59 执行一次此脚本, 执行日志位于 /var/log/nginx/cutnginxlog.log\n[root@localhost ~]# echo &#x27;59 23 * * * root /var/log/nginx/cutnginxlog.sh &gt;&gt; /var/log/nginx/cutnginxlog.log 2&gt;&amp;1&#x27; &gt;&gt; /etc/crontab\n\n参考链接官方新开日志文件操作：https://nginx.org/en/docs/control.html#logs\n按日期分割Nginx日志: https://blog.51cto.com/binghe001/5245736\n","categories":["linux"],"tags":["nginx"]},{"title":"mysql 高可用","url":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8.html","content":"环境准备准备3台已配置好 mysql MGR 集群的服务器，配置教程参考mysql-MGR搭建\n\n\n\n服务器ip\nhostname\n主从\n系统\n已安装软件\n\n\n\n192.168.31.200\ns1\n主\ncentos7.9\nmysql5.7.38\n\n\n192.168.31.201\ns2\n从\ncentos7.9\nmysql5.7.38\n\n\n192.168.31.202\ns3\n从\ncentos7.9\nmysql5.7.38\n\n\n安装 proxysqlyum安装不推荐使用此方式下载，速度太慢\n\n添加 proxysql 仓库[root@s1 rpm]# cat &gt; /etc/yum.repos.d/proxysql.repo &lt;&lt; EOF[proxysql]name=ProxySQL YUM repositorybaseurl=https://repo.proxysql.com/ProxySQL/proxysql-2.4.x/centos/\\$releasevergpgcheck=1gpgkey=https://repo.proxysql.com/ProxySQL/proxysql-2.4.x/repo_pub_keyEOF\n\n安装[root@s1 rpm]# yum install proxysql -y\n\nrpm安装推荐使用\n\n下载 rpm 包下载地址 https://github.com/sysown/proxysql/releases\n\n下载完成后上传至 /data/rpm/ 目录下\n安装[root@s1 rpm]# cd /data/rpm[root@s1 rpm]# yum install proxysql-2.4.3-1-centos7.x86_64.rpm\n\n开启端口proxysql需要开启 6032、6033 端口\n[root@s1 rpm]# firewall-cmd --zone=public --add-port=6032/tcp --permanent[root@s1 rpm]# firewall-cmd --zone=public --add-port=6033/tcp --permanent[root@s1 rpm]# firewall-cmd --reload\n\n服务管理启动[root@s1 rpm]# service proxysql start\n\n停止[root@s1 rpm]# service proxysql stop\n重启[root@s1 rpm]# service proxysql restart\n登录 proxysql 控制台proxysql 控制台默认端口是 6032，账号密码都是 admin\n[root@s1 rpm]# mysql -u admin -padmin -h 127.0.0.1 -P6032 --prompt=&#x27;Admin&gt; &#x27;\n\nproxysql有自己的控制台，不要和mysql的控制台弄混淆了\n\n配置proxy 配置间移动整套配置系统分为三层：顶层为 RUNTIME ,中间层为 MEMORY , 底层也就是持久层 DISK 和 CONFIG FILE 。\n\nRUNTIME ： 代表 ProxySQL 当前生效的正在使用的配置，无法直接修改这里的配置，必须要从下一层 “load” 进来。 \nMEMORY： MEMORY 层上面连接 RUNTIME 层，下面连接持久层。这层可以正常操作 ProxySQL 配置，随便修改，不会影响生产环境。修改一个配置一般都是现在 MEMORY 层完成的，确认正常之后在加载达到 RUNTIME 和 持久化的磁盘上。\nDISK 和 CONFIG FILE：持久化配置信息，重启后内存中的配置信息会丢失，所需要将配置信息保留在磁盘中。重启时，可以从磁盘快速加载回来。\n\nmysql配置创建监控账号创建一个监控账号用来提供给 proxysql 使用。\nmysql&gt; create user &#x27;monitor&#x27;@&#x27;%&#x27; identified by &#x27;As123456!&#x27;;mysql&gt; grant usage,replication client on *.* to monitor@&#x27;%&#x27;;mysql&gt; flush privileges;\n\nproxysql 配置设置监控使用的账号密码设置\n# 在 proxysql 数据库设置监控的账号密码Admin&gt; UPDATE global_variables SET variable_value=&#x27;monitor&#x27; WHERE variable_name=&#x27;mysql-monitor_username&#x27;;Admin&gt; UPDATE global_variables SET variable_value=&#x27;As123456!&#x27; WHERE variable_name=&#x27;mysql-monitor_password&#x27;;# 设置时间间隔Admin&gt; UPDATE global_variables SET variable_value=&#x27;2000&#x27; WHERE variable_name IN (&#x27;mysql-monitor_connect_interval&#x27;,&#x27;mysql-monitor_ping_interval&#x27;,&#x27;mysql-monitor_read_only_interval&#x27;);# 生效并保存到磁盘Admin&gt; LOAD MYSQL VARIABLES TO RUNTIME;Admin&gt; SAVE MYSQL VARIABLES TO DISK;\n\n查看是否成功\n查看临时数据是否生效\nAdmin&gt; SELECT * FROM global_variables WHERE variable_name LIKE &#x27;mysql-monitor_%&#x27;;\n\n\n查看运行时是否生效\nAdmin&gt; SELECT * FROM runtime_global_variables WHERE variable_name LIKE &#x27;mysql-monitor_%&#x27;;\n\n\n一般 proxysql 都会存在一张临时表和一张运行时表，例如 global_variables 和 runtime_global_variables ,在临时表加上前缀 runtime_ 就是运行时表\n\n添加被监控的mysql服务添加 mysql 节点\n# 添加 mysql 服务# hostgroup_id 后续复制组时会用到，这里随便设置就行Admin&gt; INSERT INTO mysql_servers(hostgroup_id,hostname,port) VALUES (1,&#x27;192.168.31.200&#x27;,3306);Admin&gt; INSERT INTO mysql_servers(hostgroup_id,hostname,port) VALUES (1,&#x27;192.168.31.201&#x27;,3306);Admin&gt; INSERT INTO mysql_servers(hostgroup_id,hostname,port) VALUES (1,&#x27;192.168.31.202&#x27;,3306);# 生效并保存到磁盘Admin&gt; LOAD MYSQL SERVERS TO RUNTIME;Admin&gt; SAVE MYSQL SERVERS TO DISK;\n\n查看是否成功\nAdmin&gt; SELECT * FROM runtime_mysql_servers;\n\n\n设置读写库proxysql 会自动区分读库与写库，然后使用 hostgroup_id 来分类\n# 设置写库的 hostgroup_id = 1， 读库的 hostgroup_id = 2Admin&gt; INSERT INTO mysql_replication_hostgroups (writer_hostgroup,reader_hostgroup,comment) VALUES (1,2,&#x27;cluster1&#x27;);# 生效并保存Admin&gt; LOAD MYSQL SERVERS TO RUNTIME;Admin&gt; SAVE MYSQL SERVERS TO DISK;\n\n查看节点读写类型\nAdmin&gt; SELECT * FROM monitor.mysql_server_read_only_log ORDER BY time_start_us DESC LIMIT 3;\n\n\n查看 hostgroup_id 是否正确\n\n\n\n添加 proxysql 用户通过定义 default_hostgroup，我们指定用户应该默认连接到哪些后端服务器（即，这将是来自特定用户的流量的默认路由，可以配置其他规则以重新路由，但是在它们不存在的情况下，所有查询都会去到特定的主机组）\n# 添加Admin&gt; INSERT INTO mysql_users(username,password,default_hostgroup) VALUES (&#x27;remote&#x27;,&#x27;As123456!&#x27;,1);# 生效并保存Admin&gt; LOAD MYSQL USERS TO RUNTIME;Admin&gt; SAVE MYSQL USERS TO DISK;\n\n验证\nAdmin&gt; select * from runtime_mysql_users;\n\n\n使用proxysql 代理的默认端口是 6033， 账号密码是在 添加 proxysql 用户 处设置的。\n[root@s1 ~]# mysql -uremote -P6033 -p\n\n统计登录 proxysql 控制台\n根据总执行时间找到前 5 个查询\nAdmin&gt; SELECT digest,SUBSTR(digest_text,0,25),count_star,sum_time FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27; ORDER BY sum_time DESC LIMIT 5;\n\n查询次数最多的 5 条sql\nAdmin&gt; SELECT digest,SUBSTR(digest_text,0,25),count_star,sum_time FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27; ORDER BY count_star DESC LIMIT 5;\n\n查询最耗时的 5 条sql\nAdmin&gt; SELECT digest,SUBSTR(digest_text,0,25),count_star,sum_time,sum_time/count_star avg_time, min_time, max_time FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27; ORDER BY max_time DESC LIMIT 5;\n\n查找按总执行时间前 5，并且最短执行时间至少为 1 毫秒：\nAdmin&gt; SELECT digest,SUBSTR(digest_text,0,20),count_star,sum_time,sum_time/count_star avg_time, min_time, max_time FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27; AND min_time &gt; 1000 ORDER BY sum_time DESC LIMIT 5;\n\n查找按总执行时间排序的前 5 个查询，平均执行时间至少为 1 秒。还显示总执行时间的百分比：\nAdmin&gt; SELECT digest,SUBSTR(digest_text,0,25),count_star,sum_time,sum_time/count_star avg_time, ROUND(sum_time*100.00/(SELECT SUM(sum_time) FROM stats_mysql_query_digest),3) pct FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27; AND sum_time/count_star &gt; 1000000 ORDER BY sum_time DESC LIMIT 5;\n\n查找按总执行时间排序的前 5 个查询，平均执行时间至少为 15 毫秒，并显示占总执行时间的百分比：\nAdmin&gt; SELECT digest,SUBSTR(digest_text,0,25),count_star,sum_time,sum_time/count_star avg_time, ROUND(sum_time*100.00/(SELECT SUM(sum_time) FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27;),3) pct FROM stats_mysql_query_digest WHERE digest_text LIKE &#x27;SELECT%&#x27; AND sum_time/count_star &gt; 15000 ORDER BY sum_time DESC LIMIT 5;\n\n读写分离通过统计里的 sql 获取到高频的查询 sql, 确定这些 sql 业务上不需要强一致后，将这些 sql 配置成使用读库查询\n根据 digest 设置规则(单一sql)\nAdmin&gt; INSERT INTO mysql_query_rules (rule_id,active,digest,destination_hostgroup,apply)VALUES(1,1,&#x27;0xE9F9F0B015ED8623&#x27;,2,1);\n\n根据 match_digest 设置规则(正则表达式匹配的sql)\nAdmin&gt; INSERT INTO mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply)VALUES(2,1,&#x27;^SELECT COUNT\\(\\*\\)&#x27;,2,1);\n生效并保存\nAdmin&gt; LOAD MYSQL QUERY RULES TO RUNTIME;Admin&gt; SAVE MYSQL QUERY RULES TO DISK;\n\n集群目前已支持集群间自动同步的数据\n\nglobal_variables (Supported from ProxySQL 2.1.x)\nmysql_query_rules\nmysql_servers\nmysql_users\nproxysql_servers\n\n设置 proxy 集群# 查看Admin&gt; select * from proxysql_servers;# 添加集群Admin&gt; INSERT INTO `proxysql_servers` (hostname, port, comment) VALUES (&#x27;192.168.31.200&#x27;, 6032, &#x27;proxysql1&#x27;);Admin&gt; INSERT INTO `proxysql_servers` (hostname, port, comment) VALUES (&#x27;192.168.31.201&#x27;, 6032, &#x27;proxysql2&#x27;);# 生效并保存Admin&gt; LOAD PROXYSQL SERVERS TO RUNTIME;Admin&gt; SAVE PROXYSQL SERVERS TO DISK;\n\n设置 proxy 监控账号信息# 查看 admin 变量Admin&gt; SELECT * FROM global_variables WHERE variable_name LIKE &#x27;admin%&#x27;;# 设置集群 proxy 监控账号密码及凭证Admin&gt; UPDATE global_variables SET variable_value=&#x27;cluster&#x27; WHERE variable_name=&#x27;admin-cluster_username&#x27;;Admin&gt; UPDATE global_variables SET variable_value=&#x27;cluster&#x27; WHERE variable_name=&#x27;admin-cluster_password&#x27;;Admin&gt; UPDATE global_variables SET variable_value=&#x27;admin:admin;cluster:cluster&#x27; WHERE variable_name=&#x27;admin-admin_credentials&#x27;;# 生效并保存Admin&gt; LOAD ADMIN VARIABLES TO RUNTIME;Admin&gt; SAVE ADMIN VARIABLES TO DISK;\n\n此处有个大坑：cluster_username 不能直接使用 admin 账号，必须新建账号，且在 admin-admin_credentials 中配置账号信息，否则不触发同步\n\n查看同步状态# 查看集群状态Admin&gt; SELECT * FROM stats_proxysql_servers_metrics;# 查看集群同步状态Admin&gt; SELECT * FROM stats_proxysql_servers_checksums;\n\n\nkeepalived 高可用配置安装yum install keepalived -y\n\n配置主节点配置global_defs &#123;  script_user root&#125;# 定义检测 proxy 是否正常运行的脚本# interval: 定时心跳间隔(秒)# fall: 失败重试次数# rise: 服务关闭后需要连续几次响应才认为服务重新启动的次数vrrp_script check_proxy &#123; script &quot;/bin/systemctl status proxysql.service&quot; interval 2 fall 2 rise 2&#125;# 优先级指定分配接口的顺序# interface: 当前机器的网卡# priority: 优先级vrrp_instance VI_01 &#123;  state MASTER  interface enp0s3  virtual_router_id 51  priority 100  # vip 配置  virtual_ipaddress &#123;    192.168.31.50  &#125;  # 执行脚本  track_script &#123;    check_proxy  &#125;&#125;\n\n从节点配置global_defs &#123;  script_user root&#125;vrrp_script check_proxy &#123;  script &quot;/bin/systemctl status proxysql.service&quot;  interval 2  fall 2  rise 2&#125;vrrp_instance VI_01 &#123;  state BACKUP  interface enp0s3  virtual_router_id 51  priority 101  # The virtual ip address shared between the two loadbalancers  virtual_ipaddress &#123;  192.168.31.50  &#125;  track_script &#123;    check_proxy  &#125;&#125;\n\n服务管理启动\nservice keepalived start\n\n关闭\nservice keepalived stop\n\n重启\nservice keepalived restart\n\n参考地址\n官方文档: https://proxysql.com/documentation/\n官方集群文档: https://proxysql.com/documentation/proxysql-cluster/   \n集群参考: https://proxysql.com/blog/proxysql-cluster/\n高可用配置: https://mysqldb-info.blogspot.com/2019/08/make-proxysql-for-high-availability.html\n\n","categories":["数据库"],"tags":["mysql","proxysql","keepalived"]},{"title":"nginx安装","url":"/nginx%E5%AE%89%E8%A3%85.html","content":"yum 安装安装依赖[root@localhost ~]# yum install yum-utils -y\n\n添加 yum 源创建 /etc/yum.repos.d/nginx.repo 文件，内容如下\n[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=0enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true\n\n安装[root@localhost ~]# yum install nginx -y\n\n开启端口如果系统开启了防火墙，需要开启端口才能远程访问\n[root@localhost rpm]# firewall-cmd --zone=public --add-port=80/tcp --permanent[root@localhost rpm]# firewall-cmd --reload\n\n服务管理启动\n[root@localhost ~]# service nginx start\n\n停止\n[root@localhost ~]# service nginx stop\n\n重启\n[root@localhost ~]# service nginx restart\n\n热启动\n[root@localhost ~]# nginx -s reload\n\n\n\n参考链接nginx官方安装说明文档：https://nginx.org/en/linux_packages.html#RHEL-CentOS\nnginx官方下载地址：https://nginx.org/en/download.html\n","categories":["linux"],"tags":["nginx"]},{"title":"jdk安装","url":"/jdk%E5%AE%89%E8%A3%85.html","content":"rpm安装下载需要登录 oracle 账号才能下载\n官方下载地址: https://www.oracle.com/java/technologies/downloads/#java8-linux\n\n安装创建文件夹\n[root@localhost ~]# mkdir -p /data/rpm/jdk[root@localhost ~]# cd /data/rpm/jdk/\n\n上传 jdk-8u341-linux-i586.rpm 到服务器的 /data/rpm/jdk 目录,然后运行以下命令安装：\n# 安装 jdk[root@localhost jdk]# yum install jdk-8u341-linux-x64.rpm -y\n\n\n验证[root@localhost jdk]# java -version\n\n\n","categories":["java"],"tags":["jdk"]},{"title":"mysql-MGR搭建","url":"/mysql-MGR%E6%90%AD%E5%BB%BA.html","content":"组复制背景全同步复制当主节点提交事务时，必须等待所有的从节点收到 binlog 日志并执行后，主节点才会提交事务。\n性能非常差，基本不会使用\n\n异步复制MySQL 默认的复制模式。有一个主（source）和一个或多个从（replica）。主节点执行事务生成 binlog，然后异步的发送到从节点的relay log, 从服务器重新执行（在基于sql语句的复制）或（基于数据行的复制）。默认情况下所有服务器都拥有数据的完整副本。\n\n假如主发生宕机并且binlog还没来得及被从接收，而切换程序将从提升为新的主，就会出现数据不一致的情况！另外，在高并发的情况下，传统的主从复制，从节点可能会与主产生较大的延迟\n\n半同步复制需要借助插件实现，半同步复制在异步复制中增加了一个同步步骤。这意味着主节点在提交时等待至少一个(可以配置个数)从节点确认它已收到事务。只有这样，主节点才会恢复提交操作。\n\n当主等待从同步成功的过程中主挂了，这个主事务提交就失败了，客户端也收到了事务执行失败的结果了，但是从上已经将binLog的内容写到Relay Log里了，这个时候，从数据就会多了，但是多了数据一般问题不算严重，多了总比少了好。\n\n组复制组复制由多个节点组成，当其中一个节点提交事务，组内多数节点可用时，就允许执行事务。保证服务器的高可用，底层使用 Paxos 算法。\n\n使用组复制的 mysql 版本必须大于等于 5.7.17, 一个组最多 9 个节点\n\n环境准备准备三台已安装mysql5.7，且可以互相访问的服务器，安装mysql5.7参考mysql 安装。\n\n\n\n服务器ip\n系统\n已安装软件\n\n\n\n192.168.31.200\ncentos7.9\nmysql5.7.38\n\n\n192.168.31.201\ncentos7.9\nmysql5.7.38\n\n\n192.168.31.202\ncentos7.9\nmysql5.7.38\n\n\n安装修改 hostname分别修改三台服务器的 hostname 为 s1、s2、s3\n# 192.168.31.200[root@localhost ~]# hostnamectl set-hostname s1# 192.168.31.201[root@localhost ~]# hostnamectl set-hostname s2# 192.168.31.202[root@localhost ~]# hostnamectl set-hostname s3\n\n在三台服务器的 /etc/hosts 文件，添加 hostname  映射\n192.168.31.200 s1192.168.31.201 s2192.168.31.202 s3\n\n开启端口# 开启 33061 端口用来 MGR 通信[root@s1 ~]# firewall-cmd --zone=public --add-port=33061/tcp --permanent# 刷新防火墙[root@s1 ~]# firewall-cmd --reload\n\n关闭 selinux关闭 selinux, 否则 MGR 会启动失败。\n先临时关闭 setenforce 0，重启服务器会失效\n然后永久关闭，修改 /etc/selinux/config ，将SELINUX=enforcing改为SELINUX=disabled\n\n调整 mysql 配置文件在 /etc/my.cnf 文件 [mysqld] 下面追加， \n配置文件如下\n# -----------------# 禁用非 innodb 引擎# -----------------disabled_storage_engines=&quot;MyISAM,BLACKHOLE,FEDERATED,ARCHIVE,MEMORY&quot;# -----------------# 复制设置# -----------------# * 服务器编号，s1=1, s2=2, s3=s3 *server_id=1# 全局事务标识符开启gtid_mode=ONenforce_gtid_consistency=ON# 同步的数据写入数据库master_info_repository=TABLErelay_log_info_repository=TABLE# 开启组复制必须设置为 NONEbinlog_checksum=NONE# 开启 binloglog_slave_updates=ONlog_bin=binlogbinlog_format=ROW# -----------------# 组复制设置# -----------------# 添加组复制插件plugin_load_add=&#x27;group_replication.so&#x27;transaction_write_set_extraction=XXHASH64# 组名，同一个组必须相同，使用 UUID 格式，可以在 mysql 控制台使用 SELECT UUID(); 命令生成group_replication_group_name=&quot;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa&quot;# 服务启动时是否自动开启组复制，推荐手动开启group_replication_start_on_boot=off# * 与组成员通信的网络地址(注意端口不是3306，是需要新开的端口)  s1=s1:33061, s2=s2:33061, s3=s3:33061*group_replication_local_address= &quot;s1:33061&quot;# 组成员group_replication_group_seeds= &quot;s1:33061,s2:33061,s3:33061&quot;# 是否引导组，设置为 offgroup_replication_bootstrap_group=off\n\n注释中开头结尾带 * 号的话，说明此行代码需要根据环境进行调整\n\n重启服务\n[root@s1 ~]# service mysqld restart\n\n创建同步账号所有节点创建同步账号\n# 临时关闭 binlog,防止污染mysql&gt; SET SQL_LOG_BIN=0;# 创建rpl_user账户，此账户用于实现主从数据同步 mysql&gt; CREATE USER rpl_user@&#x27;%&#x27; IDENTIFIED BY &#x27;As123456!&#x27;;# 赋予主从同步权限 mysql&gt; GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#x27;%&#x27;;# 让刚才的修改生效 mysql&gt; FLUSH PRIVILEGES;# 开启 binlogmysql&gt; SET SQL_LOG_BIN=1;\n\n如果忘记关闭 binlog 记录，导致 binlog 日志污染的话，加入组复制会失败。可以使用 reset master 命令重置 binlog 日志\n\n加入组复制通道所有节点使用刚刚创建的同步账号，加入组复制通道\nmysql&gt; CHANGE MASTER TO MASTER_USER=&#x27;rpl_user&#x27;, MASTER_PASSWORD=&#x27;As123456!&#x27; FOR CHANNEL &#x27;group_replication_recovery&#x27;;\n\n\n\n启动组复制启动组整个组需要由单个节点来首次开启组复制，我们在配置文件中设置为关闭了自动引导组group_replication_bootstrap_group=off，所以这里我这里我们使用s1来手动开启：\n# 开启引导组mysql&gt; SET GLOBAL group_replication_bootstrap_group=ON;# 启动组复制mysql&gt; START GROUP_REPLICATION;# 关闭引导组mysql&gt; SET GLOBAL group_replication_bootstrap_group=OFF;\n\n启动完成后查看组成员，可以看到s1已经成功开启组复制了。\nmysql&gt; SELECT * FROM performance_schema.replication_group_members;\n\n\n节点加入引导组完成后，从节点只需要启动即可\nmysql&gt; START GROUP_REPLICATION;\n\ns2、s3 加入节点后，检查是否加入成功\nmysql&gt; SELECT * FROM performance_schema.replication_group_members;\n\n\n节点退出mysql&gt; STOP GROUP_REPLICATION;\n\n验证查看集群情况mysql&gt; SELECT * FROM performance_schema.replication_group_members;\n\n查看当前节点状态mysql&gt; SELECT * FROM performance_schema.replication_group_member_stats;\n\n查看主节点如下图可以看出s1是主库，s2、s3 是从库。\nmysql&gt; SHOW STATUS LIKE &#x27;group_replication_primary_member&#x27;;\n\n\n模拟主从切换s1 退出并查看情况# s1 退出节点mysql&gt; STOP GROUP_REPLICATION;# s1 查看组员mysql&gt; SELECT * FROM performance_schema.replication_group_members;\n\n\n可以看到 s1 是 OFFLINE 状态，并且看不到其他节点\ns2 或 s3 查看节点情况# 查看组员mysql&gt; SELECT * FROM performance_schema.replication_group_members;# 查看主节点mysql&gt; SHOW STATUS LIKE &#x27;group_replication_primary_member&#x27;;\n\n\n可以看到 s2 变成了主节点\ns1 重新加入组，并查看情况# 重新加入组mysql&gt; START GROUP_REPLICATION;# 查看组员mysql&gt; SELECT * FROM performance_schema.replication_group_members;# 查看主节点mysql&gt; SHOW STATUS LIKE &#x27;group_replication_primary_member&#x27;;\n\n\n可以看到主节点仍然是 s2, 并不会切换成 s1\n服务运行后加入新节点当加入新节点时，原来的组可能已经运行了很久，binlog 日志会很大，或者被删除过，这样会导致数据恢复时间过长或者加入节点失败。所以需要将组里的数据直接备份到新的节点上(需要保留 GTID )，这样只需同步后面新生成的 binlog 就行了。\n备份组数据库在新节点通过 mysqldump 远程备份 MGR 的整个库，最好使用从节点，防止浪费主节点带宽\n[root@localhost ~]# mysqldump --all-databases --single-transaction --triggers --routines --host=192.168.31.200 --port=3306 --user=remote --password=As123456! &gt; dump.sql\n\n一定要加上 --single-transaction  , 否则会锁表，导致生产环境不可用\n\n加入新增节点先注释 my.cnf 里的 disabled_storage_engines，因为 mysql 系统表必须使用 MyISAM 引擎(5.7是这样，其他版本不确定)\n# disabled_storage_engines=&quot;MyISAM,BLACKHOLE,FEDERATED,ARCHIVE,MEMORY&quot;\n\n在新节点上运行备份数据\n[root@localhost ~]# mysql -u remote -pAs123456! &lt; dump.sql\n\n再开启 my.cnf 里的 disabled_storage_engines\ndisabled_storage_engines=&quot;MyISAM,BLACKHOLE,FEDERATED,ARCHIVE,MEMORY&quot;\n\n加入组复制通道\nmysql&gt; CHANGE MASTER TO MASTER_USER=&#x27;rpl_user&#x27;, MASTER_PASSWORD=&#x27;As123456!&#x27; FOR CHANNEL &#x27;group_replication_recovery&#x27;;\n\n启动组\nSTART GROUP_REPLICATION;\n\n在其他组成员的 my.cnf 的 group_replication_group_seeds 里加上当前新节点，以确保下次重启时能够识别到此新加入的节点。\n结语MGR 发生故障时，虽然可以实现自动主从切换，但是无法提供固定的访问入口，客户端连接时仍需要通过第三方工具来实现。这里推荐使用 proxysql，参考mysql 高可用\n参考地址官方文档：https://dev.mysql.com/doc/refman/5.7/en/group-replication.html\nMGR搭建过程中遇到的错误以及解决办法: https://cloud.tencent.com/developer/article/1533657\n半同步复制的问题: https://zhuanlan.zhihu.com/p/367194130\n添加第4个节点到MGR中：https://dba.stackexchange.com/questions/214416/adding-4th-node-in-mysql-group-replication-stuck-at-recovering\n","categories":["数据库"],"tags":["mysql","centos"]},{"title":"node 版本切换","url":"/node%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2.html","content":"安装nvm下载地址：https://github.com/coreybutler/nvm-windows/releases\n\n使用查看版本nvm list\n\n\n安装nvm install &lt;node版本号&gt;\n\n\n使用需要以管理员身份运行 CMD\nnvm use &lt;node版本号&gt;\n\n\n卸载\n","categories":["前端"],"tags":["node"]},{"title":"mysql 安装","url":"/mysql%E5%AE%89%E8%A3%85.html","content":"yum安装不推荐，而且每次安装都要重复下载，而且国内下载速度太慢\n环境系统：centos7.9\n依赖：wget、yum-utils\n下载 yum源官方yum源：https://dev.mysql.com/downloads/repo/yum/\n\n# 下载 yum 源[root@localhost ~]# wget --no-check-certificate https://dev.mysql.com/get/mysql80-community-release-el7-7.noarch.rpm# 安装 yum 源[root@localhost ~]# yum localinstall mysql80-community-release-el7-7.noarch.rpm\n\n切换 mysql 版本查看当前版本yum repolist all | grep mysql\n\n\n切换版本从上一步可以看到 MySQL 8.0 是 enabled 状态，本文安装 MySQL 5.7， 所以需要切换下\n# 关闭8.0，开启5.7[root@localhost ~]# yum-config-manager --disable mysql80-community[root@localhost ~]# yum-config-manager --enable mysql57-community# 验证是否切换成功[root@localhost ~]# yum repolist enabled | grep mysql\n\n\n安装[root@localhost ~]# yum install mysql-community-server\n\n安装完后请查看初始化\nrpm 安装推荐使用此安装方式\n环境系统：centos7.9\n下载 rpm 包下载地址 https://downloads.mysql.com/archives/community/\n\n上传至服务器 /data/rpm/ 目录，\n# 解压[root@mycentos7 ~]# cd /data/rpm[root@mycentos7 rpm]# tar xvf mysql-5.7.38-1.el7.x86_64.rpm-bundle.tar\n\n解压后如下\n\nmysql-community-test-5.7.38-1.el7.x86_64.rpm 是测试的，可以自行删除\n安装运行安装命令\n[root@localhost rpm]# yum install mysql-community-*\n\n\n安装完后请查看初始化\n初始化启动服务，查看临时密码[root@localhost rpm]# service mysqld start[root@localhost rpm]# grep &#x27;temporary password&#x27; /var/log/mysqld.log\n\n\n修改初始密码# 登录mysql&gt; mysql -uroot -p# 此处密码设置为 As123456!mysql&gt; ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;As123456!&#x27;;\n\n\n\n创建远程连接账号# 创建一个远程连接用户，用来远程连接mysql&gt; create user &#x27;remote&#x27;@&#x27;%&#x27; identified by &#x27;As123456!&#x27;; #为fgoc用户赋予所有数据库资源的访问权限mysql&gt; grant all privileges on *.* to remote@&#x27;%&#x27;;# 让刚才的修改生效mysql&gt; FLUSH PRIVILEGES;\n\n开启端口如果系统开启了防火墙，需要开启端口才能远程访问\n[root@localhost rpm]# firewall-cmd --zone=public --add-port=3306/tcp --permanent[root@localhost rpm]# firewall-cmd --reload\n\n参考文档官方文档：https://dev.mysql.com/doc/refman/5.7/en/installing.html\n","categories":["数据库"],"tags":["mysql","centos","yum"]},{"title":"工具推荐","url":"/%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90.html","content":"在线\nexcalidraw 画图 https://excalidraw.com/\ndraw.io流程图 https://app.diagrams.net/\ntrello 工作备忘录 https://trello.com/\n\n客户端\nAnotherRedisDesktopManager redis管理工具 https://github.com/qishibo/AnotherRedisDesktopManager\nsourcetree git管理 https://www.sourcetreeapp.com/\npicgo 图床 https://github.com/Molunerfinn/PicGo/releases\nwindirstat windows磁盘占用扫描工具 https://windirstat.net/download.html\nscreentogif gif录制 https://www.screentogif.com/\nCaptura 屏幕录制 https://mathewsachin.github.io/Captura/\nwinscp ssh远程工具 https://winscp.net/eng/docs/lang:chs\ntodesk 远程控制 https://www.todesk.com/\ntypora markdown文档 https://typora.io/\nRobo 3T mongodb管理 https://robomongo.org/#\n7zip 文件压缩 https://www.7-zip.org/\n有道云笔记 笔记 https://note.youdao.com/\nVirtualBox 虚拟机 https://www.virtualbox.org/\n数据库导出数据字典 https://gitee.com/dotnetchina/DBCHM\n\n","categories":["其他"],"tags":[]},{"title":"redis哨兵配置","url":"/redis%E5%93%A8%E5%85%B5%E9%85%8D%E7%BD%AE.html","content":"环境准备\n\n\n服务器ip\n系统\n\n\n\n192.168.31.200\ncentos7.9\n\n\n192.168.31.201\ncentos7.9\n\n\n192.168.31.202\ncentos7.9\n\n\n安装centos 默认 yum 源没有 redis 的 rpm，需要使用第三方的 rpm。\n下载此处下载 redis-7.0.4-1 ，其他版本自行下载\nhttps://rhel.pkgs.org/7/remi-x86_64/redis-7.0.5-2.el7.remi.x86_64.rpm.html\n\n安装# 创建文件夹，之后上传下载的 rpm 包到此目录[root@localhost redis]# mkdir -p /data/rpm/redis# 安装[root@localhost redis]# cd /data/rpm/redis[root@localhost redis]# yum install redis-7.0.4-1.el7.remi.x86_64.rpm -y\n\n服务管理启动\n[root@localhost redis]# service redis start\n\n停止\n[root@localhost redis]# service redis stop\n\n重启\n[root@localhost redis]# service redis restart\n\n配置配置允许外部访问配置文件位于 /etc/redis.conf\n# 修改成允许外部连接访问, 线上环境最好指定 ipbind 0.0.0.0# 设置密码，线上环境必须配置，否则有安全问题requirepass As123456!\n\n配置主从只需要从服务器配置即可\n# 设置主服务的ip和端口slaveof 192.168.31.200 6379\n\n配置哨兵配置文件位于 /etc/redis-sentinel.conf\n# 修改成允许外部连接访问bind 0.0.0.0# mymaster：自定义的参数，用来定义 master 别名，供其他参数使用# 192.168.31.201: master 的 ip# 6379：master 的端口# 2： 表示至少 2 台哨兵认为 master 不可访问，才认定 master 故障，再进行故障转移sentinel monitor mymaster 192.168.31.201 6379 2\n\n启动哨兵\n# &amp; 表示后台启动redis-sentinel /etc/redis-sentinel.conf &amp;\n\n检测哨兵下面的 mymaster 为上文配置的 master 别名\n# 获取当前主节点信息地址信息SENTINEL get-master-addr-by-name mymaster# 获取主节点信息SENTINEL MASTER mymaster# 获取从节点信息SENTINEL slaves mymaster# 获取其他哨兵信息SENTINEL sentinels mymaster\n\n参考链接官方主从模式文档: https://redis.io/topics/replication官方哨兵模式文档: https://redis.io/topics/sentinel\n","categories":["数据库"],"tags":["redis"]},{"title":"nginx高可用搭建","url":"/nginx%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA.html","content":"环境准备\n\n\n服务器简称\nip\n系统\n软件\n\n\n\nnode1\n192.168.31.200\ncentos7.9\nnginx\n\n\nnode2\n192.168.31.201\ncentos7.9\nnginx\n\n\nnginx安装参考 nginx安装\n安装 keepalived在 node1 和 node2 都安装 keepalived\n[root@localhost ~]# yum install keepalived -y\n\n配置 keepalived修改服务器的 /etc/keepalived/keepalived.conf 配置文件\nnode1(主)global_defs &#123;  # root 用户执行脚本  script_user root&#125;# 定义检测 nginx 是否正常运行的脚本vrrp_script check_nginx &#123;  # 检测脚本  script &quot;/bin/systemctl status nginx.service&quot;  # interval: 定时心跳间隔(秒)  interval 2  # fall: 失败重试次数  fall 2  # rise: 服务关闭后需要连续几次响应才认为服务重新启动的次数  rise 2&#125;# virtual_router_id: vrrp_instance的唯一IDvrrp_instance VI_01 &#123;  # * MASTER(主)/BACKUP(备) *  state MASTER  # interface: 网卡，ip add 命令查看  interface enp0s3  # vrrp_instance的唯一ID  virtual_router_id 151  # * 权重，主节点要高于从节点 *  priority 110  # 虚拟ip  virtual_ipaddress &#123;    192.168.31.50/24  &#125;  # 调用的脚本  track_script &#123;    check_nginx  &#125;  authentication &#123;    auth_type PASS    auth_pass 123456  &#125;&#125;\n\nnode2(从)global_defs &#123;  # root 用户执行脚本  script_user root&#125;# 定义检测 nginx 是否正常运行的脚本vrrp_script check_nginx &#123;  # 检测脚本  script &quot;/bin/systemctl status nginx.service&quot;  # interval: 定时心跳间隔(秒)  interval 2  # fall: 失败重试次数  fall 2  # rise: 服务关闭后需要连续几次响应才认为服务重新启动的次数  rise 2&#125;# virtual_router_id: vrrp_instance的唯一IDvrrp_instance VI_01 &#123;  # * MASTER(主)/BACKUP(备) *  state BACKUP  # interface: 网卡，可以通过 &#x27;ip add&#x27; 命令查看  interface enp0s3  # vrrp_instance的唯一ID  virtual_router_id 151  # * 权重，主节点要高于从节点 *  priority 100  # 虚拟ip  virtual_ipaddress &#123;    192.168.31.50/24  &#125;  # 调用的脚本  track_script &#123;    check_nginx  &#125;  authentication &#123;    auth_type PASS    auth_pass 123456  &#125;&#125;\n\n注释前后带 * 号包围的表示主从配置不一致\n\n开启防火墙关闭 selinux如果开启了 selinux，需要关闭\n临时关闭[root@localhost ~]# setenforce 0\n\n永久关闭修改 /etc/selinux/config ，将 SELINUX 设置为 disabled\n防火墙开放 VRRP如果开启了 firewall ，需要开放 VRRP，运行以下命令开启\n[root@localhost ~]# firewall-cmd --add-rich-rule=&#x27;rule protocol value=&quot;vrrp&quot; accept&#x27; --permanent[root@localhost ~]# firewall-cmd --reload\n\n服务管理启动\n[root@localhost ~]# service keepalived start\n\n关闭\n[root@localhost ~]# service keepalived stop\n\n重启\n[root@localhost ~]# service keepalived restart\n\n验证验证 keepalived\n运行 ip add 查看是否生成 vip，可以看到 vip 指向了 node1 服务器\n[root@localhost ~]# ip add\n\n\n\n关闭 node1 上的 nginx 后再次查看，可以看到 vip 指向了 node2 服务器\n[root@localhost ~]# service nginx stop\n\n\n\nnode1 重新启动 nginx 后再次查看，可以看到 vip 重新指向了 node1 服务器\n[root@localhost ~]# service nginx start\n\n\n\n\n验证 nginx\n修改 node1 和 node2 的 /usr/share/nginx/html/index.html 的访问页面\nnode1\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;这是 node1 服务器的 nginx 首页！！！&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\n\nnode2\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;这是 node1 服务器的 nginx 首页！！！&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\t\n\n使用 vip 访问测试\n\n\n关闭 node1 服务器的 nginx, 再次访问\n[root@localhost ~]# service nginx stop\n\n\n\n启动 node1 服务器的 nginx, 再次访问\n[root@localhost ~]# service nginx start\n\n\n\n\n​    \n参考链接nginx+keepalived高可用搭建： https://www.linuxtechi.com/setup-highly-available-nginx-keepalived-linux/\n","categories":["linux"],"tags":["keepalived","nginx"]},{"title":"jar 包装成 windows 服务","url":"/jar%E6%B3%A8%E5%86%8C%E5%88%B0windows%E6%9C%8D%E5%8A%A1.html","content":"下载 Windows Service Wrapper下载地址：https://github.com/winsw/winsw\n使用复制 WinSW.NET4.exe 到 jar 文件同级目录，并改名为jar的相同文件名\n在同目录创建xml配置文件，与 jar文件同名， 内容如下\n&lt;configuration&gt;&lt;id&gt;test&lt;/id&gt;&lt;name&gt;test&lt;/name&gt;&lt;description&gt;This is test jar.&lt;/description&gt;&lt;executable&gt;java&lt;/executable&gt;&lt;arguments&gt;-Xms512m -Xmx512m -jar  test.jar --spring.profiles.active=dev&lt;/arguments&gt;&lt;!-- 开机启动 --&gt;&lt;startmode&gt;Automatic&lt;/startmode&gt;&lt;logpath&gt;./logs&lt;/logpath&gt;&lt;log mode=&quot;roll-by-time&quot;&gt;&lt;pattern&gt;yyyyMMdd&lt;/pattern&gt;&lt;/log&gt;&lt;/configuration&gt;\n\n运行 cmd 命令注册成 windows 服务\ntest.exe install\n\n使用# 启动命令net start test# 停止命令net stop test# 卸载命令, 如果卸载不了，使用管理员模式打开cmd再运行sc delete test\n\n参考链接https://www.cnblogs.com/wangchaonan/p/12102150.html\n","categories":["java"],"tags":["jar"]},{"title":"idea 快捷键","url":"/idea%E5%BF%AB%E6%8D%B7%E9%94%AE.html","content":"代码相关\n\n\n快捷键\n说明\n\n\n\nAlt+Insert\nget、set等代码生成\n\n\nCtrl+O\n重写或实现方法\n\n\nCtrl+Alt+T\ntrycatch等快捷方式\n\n\nCtrl+Alt+L\n代码格式化\n\n\nCtrl+Alt+O\n删除无用的import\n\n\nCtrl+Shift+U\n大小写转换\n\n\n搜索\n\n\n快捷键\n说明\n\n\n\n双击Shift\n搜索任何位置\n\n\nCtrl+N\n查找类名\n\n\nCtrl+Shift+N\n查找文件名\n\n\nCtrl+F\n搜索当前文件的代码\n\n\nCtrl+Shift+F\n搜索全部文件的代码\n\n\nCtrl+R\n替换当前文件的代码\n\n\nCtrl+Shift+R\n替换全部文件的代码\n\n\n跳转\n\n\n快捷键\n说明\n\n\n\nCtrl+G\n跳转到指定行\n\n\nCtrl+E\n跳转到上一个文件\n\n\nCtrl+Shift+Backspcace\n跳转到上一次修改代码的地方\n\n\nAlt+↓↑\n跳转到下或上个方法\n\n\nAlt+]/[\n跳转到括号的开始或结尾\n\n\nF2/Shift+F2\n跳转到下/上一个高亮错误提示位置\n\n\nF4\n跳转到定义的位置\n\n\nF11\n添加备注\n\n\nCtrl+F11\n添加备注，并打上数字标记\n\n\nCtrl+0-9\n跳转到备注位置\n\n\nShift+F11 / Alt+2\n显示备注列表弹框/侧边栏\n\n\nCtrl+Tab\n显示当前打开的文件弹框\n\n\n类相关\n\n\n\n快捷键\n说明\n\n\n\nAlt+F7\n查看字段，方法，类的所有使用过地方\n\n\nCtrl+Shift+I\n弹框显示定义的代码(不需要跳转到源文件)\n\n\nAlt+7/Ctrl+F12\n侧边/弹框查看当前类的类结构(构造器，属性，方法)\n\n\nCtrl+H\n查看当前类的继承关系\n\n\nCtrl+Shift+H\n查看当前方法的子类重写\n\n\n\n官方快捷键参考\n","categories":["编辑器"],"tags":["idea"]},{"title":"docker 常用命令","url":"/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html","content":"镜像命令查看本地镜像docker images [options]\n\n-a 列出本地所有镜像\n-q 只显示镜像id\n–digest 显示摘要信息\n–no-trunc 显示所有信息\n\n搜索远程镜像docker search [options] 镜像名\n\n–no-trunc 显示所有信息\n-s 列出收藏数不少于指定值的镜像\n–automated 只列出 automated build 类型的镜像\n\n下载远程镜像docker pull 镜像名字[:TAG]\n删除本地镜像删除单个\ndocker rmi -f 镜像id\n\n删除多个\ndocker rmi -f 镜像名1:TAG 镜像名2:TAG\n\n删除全部\ndocker rmi -f $&#123;docker images -qa&#125;\n\n容器命令新建并启动容器docker run [options] 镜像 [COMMAND][ARG...]\n\n–name=”容器新名字”: 为容器指定一个名称\n-d: 后台运行容器\n-i: 以交互模式运行，与-t一起使用\n-t: 为容器重新分配一个伪输入终端，与 -i 一起使用\n-p: 指定端口映射，有四种格式\n\nip:hostPort:containerPortip::containerPorthostPort:containerPortcontainerPort\n\n列出运行的容器docker ps [options]\n\n\n-a :列出当前所有正在运行的容器+历史上运行过的\n\n-l :显示最近创建的容器。\n\n-n：显示最近n个创建的容器。\n\n-q :静默模式，只显示容器编号。\n\n–no-trunc :不截断输出。\n\n\n退出容器exit\n\n启动容器docker start 容器id或容器名\n\n重启容器docker restart 容器id或容器名\n\n关闭容器docker stop 容器id或容器名\n\n强制关闭容器docker kill 容器id或容器名\n\n删除已停止的容器## 删除单个docker rm 容器id## 删除多个docker rm -f $&#123;docker ps -a -q&#125;\n\n与已启动的容器交互## 在容器中打开新终端docker exec -it 容器id 命令## 直接使用容器中的终端docker attach 容器id\n\n从容器拷贝文件到主机docker cp 容器id:容器内路径 本机路径\n\n提交镜像docker commit -m=&quot;描述信息&quot; -a=&quot;作者&quot; 容器id 要生成的镜像名:[标签名]\n\n查看占用空间docker system df -v\n\n删除未使用的镜像docker image prune\n\n删除未使用的容器docker container prune\n\n","categories":["linux"],"tags":["docker"]},{"title":"本地 yum 安装","url":"/centos%E6%9C%AC%E5%9C%B0yum%E5%AE%89%E8%A3%85.html","content":"安装插件centos 低版本没有 downloadonly 属性，需要下载 yum 插件来支持\n# centos5[root@localhost ~]# yum install yum-downloadonly# centos6[root@localhost ~]# yum install yum-plugin-downloadonly\n\n使用# 创建用来存 rpm 包的文件夹[root@localhost ~]# mkdir /data/rpm -p# 下载 keepalived 的 rpm 及依赖的 rpm 包到 /data/rpm m目录下[root@localhost ~]# yum install –-downloadonly –-downloaddir=/data/rpm keepalived# 安装 keepalived[root@localhost ~]# cd /data/rpm/[root@localhost ~]# yum localinstall *.rpm -y\n\n\n\n\n参考链接https://www.cnblogs.com/nmap/p/9511848.html\n","categories":["linux"],"tags":["centos","yum"]},{"title":"centos 升级 openssh","url":"/centos%E5%8D%87%E7%BA%A7openssh.html","content":"安装telnet备用（可选)安装新的ssh之后，只要配置好启动，就可以做到无缝切换，但是中途断开就不能连接了，为了防止这种情况，我们可以安装telnet当作备用，若是你能保证中途不会断开，此步骤可以忽略\n\n安装\nyum install telnet telnet-server -y\n启动\n[root@localhost openssh]# systemctl enable telnet.socketCreated symlink from /etc/systemd/system/sockets.target.wants/telnet.socket to /usr/lib/systemd/system/telnet.socket.[root@localhost openssh]# systemctl start telnet.socket\n连接\n# 创建临时登录的用户[root@localhost openssh]# useradd testuser[root@localhost openssh]# passwd testuserChanging password for user testuser.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully.# 本地测试[root@localhost openssh]# telnet 127.0.0.1Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &#x27;^]&#x27;.Kernel 3.10.0-1160.el7.x86_64 on an x86_64localhost login: testuserPassword:# 切换 root 账号[testuser@localhost ~]$ su rootPassword:[root@localhost testuser]#\n\n升级 openssh下载地址https://cdn.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-9.0p1.tar.gz\n安装依赖包\nyum install zlib-devel  openssl-devel  pam-devel gcc-c++ -y\n\n备份\n[root@localhost openssh]# mkdir /etc/ssh_old[root@localhost openssh]# mv /etc/ssh/* /etc/ssh_old/\n\n解压、编译安装\n# 解压[root@localhost openssh]# tar xzvf openssh-9.0p1.tar.gz[root@localhost openssh]# cd openssh-9.0p1# 编译安装[root@localhost openssh-9.0p1]# ./configure --prefix=/usr/ --sysconfdir=/etc/ssh --with-ssl-dir=/usr/local/lib64/ --with-zlib --with-pam --with-md5-password --with-ssl-engine --with-selinux[root@localhost openssh-9.0p1]# make &amp;&amp; make install# 验证[root@localhost openssh-9.0p1]# ssh -VOpenSSH_9.0p1, OpenSSL 1.0.2k-fips  26 Jan 2017\n\n配置1.修改sshd_config\n# 修改 PermitRootLogin，允许使用 root 远程登录PermitRootLogin yes\n\n2.启动\n# 移走以前的ssh服务, 防止与新的冲突[root@localhost openssh-9.0p1]# mv /usr/lib/systemd/system/sshd.service /etc/ssh_old/sshd.service[root@localhost openssh-9.0p1]# mv /usr/lib/systemd/system/sshd.socket /etc/ssh_old/sshd.socket# 在解压包中拷贝一些文件[root@localhost openssh-9.0p1]# cp -a contrib/redhat/sshd.init /etc/init.d/sshd# 重启[root@localhost openssh-9.0p1]# service sshd restartReloading systemd:                                         [  OK  ]Restarting sshd (via systemctl):                           [  OK  ][root@localhost openssh-9.0p1]# systemctl daemon-reload# 添加自启动[root@localhost openssh-9.0p1]# chkconfig --add sshd[root@localhost openssh-9.0p1]# chkconfig sshd on\n\n关闭 telnetsystemctl stop telnet.socketsystemctl disable telnet.socket\n\n参考地址https://segmentfault.com/a/1190000022756834\n","categories":["linux"],"tags":["centos"]},{"title":"centos7.9 降级 7.5","url":"/centos7.9%E9%99%8D%E7%BA%A77.5.html","content":"centos7.9 降级 7.5下载 Centos 7.5 的rpm包\nwget --no-check-certificate https://www.repo.cloudlinux.com/cloudlinux/migrate/release-files/centos/7/x86_64/centos-release-7-5.1804.el7.centos.x86_64.rpm\n\n安装\nrpm -Uvh --oldpackage centos-release-7-5.1804.el7.centos.x86_64.rpm\n\n重启\nreboot\n\n参考链接https://www.its203.com/article/weixin_45214930/118481574\n","categories":["linux"],"tags":["centos"]},{"title":"idea常用插件","url":"/%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6.html","content":"快捷搜索接口【RestfulTool】快捷搜索接口，及简化版的postman功能\n\n\nmybatis插件【MybatisCodeHelperPro】mybatis提示跳转的等，免费功能已满足日常使用\n快捷键提示【Key Promoter X】常用快捷键提示及设置,多次操作idea上某个功能后会在右下角提示该功能的快捷键\nmvn插件【MavenHelper】mvn快捷键\n翻译【Translation】翻译\ngit提交记录【GitToolBox】显示每一行代码由谁提交\n驼峰转换【CamelCase】驼峰下划线等风格转换\njson字符串转对象【GsonFormatPlus】json文本自动生成javaBean\n对象转json字符串【POJO to JSON】javabean转json字符串\n背景图【Background Images Plus +】编辑器背景图\n","categories":["编辑器"],"tags":["idea"]},{"title":"xml 自动转 javabean","url":"/xml%E8%BD%ACjavabean.html","content":"根据 xml 生成 xsd 文件使用 idea 打开 xml 文件, 鼠标右键点击, 然后点击如下图位置生成 xsd 文件, 注意要选择 local elements/types\n\n\n根据 xsd 生成带有 jaxb 注解的 javabean\n\njaxb 工具类import javax.xml.bind.JAXBContext;import javax.xml.bind.Marshaller;import javax.xml.bind.Unmarshaller;import java.io.StringReader;import java.io.StringWriter;public class JaxbUtil &#123;  /**   * JavaBean转换成xml   * 默认编码UTF-8   * @param obj   * @param writer   * @return   */  public static String convertToXml(Object obj) &#123;    return convertToXml(obj, &quot;UTF-8&quot;);  &#125;  /**   * JavaBean转换成xml   * @param obj   * @param encoding   * @return   */  public static String convertToXml(Object obj, String encoding) &#123;    String result = null;    try &#123;      JAXBContext context = JAXBContext.newInstance(obj.getClass());      Marshaller marshaller = context.createMarshaller();      marshaller.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, true);      marshaller.setProperty(Marshaller.JAXB_ENCODING, encoding);      StringWriter writer = new StringWriter();      marshaller.marshal(obj, writer);      result = writer.toString();    &#125; catch (Exception e) &#123;      e.printStackTrace();    &#125;    return result;  &#125;  /**   * xml转换成JavaBean   * @param xml   * @param c   * @return   */  @SuppressWarnings(&quot;unchecked&quot;)  public static &lt;T&gt; T converyToJavaBean(String xml, Class&lt;T&gt; c) &#123;    T t = null;    try &#123;      JAXBContext context = JAXBContext.newInstance(c);      Unmarshaller unmarshaller = context.createUnmarshaller();      t = (T) unmarshaller.unmarshal(new StringReader(xml));    &#125; catch (Exception e) &#123;      e.printStackTrace();    &#125;    return t;  &#125;&#125;\n\n测试import com.caac.imf.api.IMFClient;import com.caac.imf.api.IMFClientFactory;import com.chun.test.xml.JaxbUtil;import com.chun.test.xml.MSG;/** * @Author chun * @Date 2019/7/26 10:58 */public class test &#123;    public static void main(String[] args) &#123;        String xml = &quot;&lt;?xml version=\\&quot;1.0\\&quot; encoding=\\&quot;UTF-8\\&quot;?&gt;&quot; +                &quot;&lt;MSG&gt;&quot; +                &quot;    &lt;META&gt;&quot; +                &quot;        &lt;SNDR&gt;FIMS&lt;/SNDR&gt;&quot; +                &quot;        &lt;RCVR&gt;&lt;/RCVR&gt;&quot; +                &quot;        &lt;SEQN&gt;1&lt;/SEQN&gt;&quot; +                &quot;        &lt;DDTM&gt;2010010223000&lt;/DDTM&gt;&quot; +                &quot;        &lt;TYPE&gt;DFOE&lt;/TYPE&gt;&quot; +                &quot;        &lt;STYP&gt;DFDE&lt;/STYP&gt;&quot; +                &quot;    &lt;/META&gt;&quot; +                &quot;    &lt;DFLT&gt;&quot; +                &quot;        &lt;FLID&gt;657423&lt;/FLID&gt;&quot; +                &quot;        &lt;FFID&gt;3U-8898-20100103081030-A&lt;/FFID&gt;&quot; +                &quot;        &lt;FLTK&gt;W/Z&lt;/FLTK&gt;&quot; +                &quot;    &lt;/DFLT&gt;&quot; +                &quot;&lt;/MSG&gt;&quot;;        MSG msg = JaxbUtil.converyToJavaBean(xml, MSG.class);        System.out.println(msg.getDFLT().getFFID());        String res = JaxbUtil.convertToXml(msg);        System.out.println(res);    &#125;&#125;\n\n输出结果\n3U-8898-20100103081030-A&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;MSG&gt;    &lt;META&gt;        &lt;SNDR&gt;FIMS&lt;/SNDR&gt;        &lt;RCVR&gt;&lt;/RCVR&gt;        &lt;SEQN&gt;1&lt;/SEQN&gt;        &lt;DDTM&gt;2010010223000&lt;/DDTM&gt;        &lt;TYPE&gt;DFOE&lt;/TYPE&gt;        &lt;STYP&gt;DFDE&lt;/STYP&gt;    &lt;/META&gt;    &lt;DFLT&gt;        &lt;FLID&gt;657423&lt;/FLID&gt;        &lt;FFID&gt;3U-8898-20100103081030-A&lt;/FFID&gt;        &lt;FLTK&gt;W/Z&lt;/FLTK&gt;    &lt;/DFLT&gt;&lt;/MSG&gt;\n\n\n\n参考链接：https://blog.csdn.net/qq_36874292/article/details/88687945\n","categories":["编辑器"],"tags":["idea","xml"]},{"title":"表单校验","url":"/%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C.html","content":"简介为什么要用传统的表单校验需要使用大量的ifelse,这样虽然可以实现校验的功能，但是确实代码的可读性非常的差，而且，如下图：\n\n使用简单使用引入 maven 依赖\n&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;&lt;/dependency&gt;\n\n创建验证对象\nimport lombok.Data;import javax.validation.constraints.NotBlank;import javax.validation.constraints.Pattern;import java.io.Serializable;@Datapublic class TestForm &#123;    @NotNull(message = &quot;日期不能为空&quot;)    private Date Date;    @NotBlank(message = &quot;进出不能为空&quot;)    private String io;    @NotNull(message = &quot;类型不能为空&quot;)    private Integer type;&#125;\n\n使用@Valid校验, 并将结果存在BindingResult中\npublic R test(@Valid @RequestBody TestForm test, BindingResult bindingResult) &#123;    if(bindingResult.hasErrors())&#123;        for (ObjectError objectError: bindingResult.getAllErrors()) &#123;            return R.error(objectError.getDefaultMessage());        &#125;    &#125;    return R.ok();&#125;\n\n内部类校验在要校验的属性上加上 @Valid 注解\nimport lombok.Data;import javax.validation.Valid;import java.util.Date;import java.util.List;@Datapublic class UserVO &#123;    /**     * 男性用户     */    @Valid    private List&lt;User&gt; mans;    /**     * 女性用户     */    @Valid    private List&lt;User&gt; womans;    @Data    public static class UserVO &#123;        /**         * id         */        private Long id;        /**         * 姓名         */        @NotBlank(message = &quot;姓名不能为空&quot;)        private String name;    &#125;&#125;\n\nspring 统一异常处理全局异常拦截器import cn.hutool.core.util.StrUtil;import com.itran.fgoc.common.core.api.Response;import com.itran.fgoc.common.core.api.ResultCode;import lombok.extern.slf4j.Slf4j;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import org.springframework.dao.DuplicateKeyException;import org.springframework.validation.BindException;import org.springframework.validation.FieldError;import org.springframework.web.bind.MethodArgumentNotValidException;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.RestControllerAdvice;import javax.validation.ConstraintViolationException;@RestControllerAdvice@Order(Ordered.HIGHEST_PRECEDENCE)@Slf4jpublic class MyGlobalExceptionHandler &#123;    @ExceptionHandler(value = ApiException.class)    public Response handle(ApiException e) &#123;        if (e.getErrorCode() != null) &#123;            if(StrUtil.isNotBlank(e.getMsg()))&#123;                log.info(e.getMsg(), e);                return Response.failed(e.getErrorCode(), e.getMsg());            &#125;            return Response.failed(e.getErrorCode());        &#125;        log.info(e.getMessage(), e);        return Response.failed(e.getMessage());    &#125;    @ExceptionHandler(value = BindException.class)    public Response validExceptionHandler(BindException e) &#123;        log.info(e.getMessage(), e);        FieldError fieldError = e.getBindingResult().getFieldError();        return Response.failed(ResultCode.VALIDATE_FAILED, fieldError.getDefaultMessage());    &#125;    @ExceptionHandler(value = ConstraintViolationException.class)    public Response constraintViolationExceptionHandler(ConstraintViolationException e) &#123;        log.info(e.getMessage(), e);        return Response.failed(ResultCode.VALIDATE_FAILED, e.getConstraintViolations().iterator().next().getMessage());    &#125;    @ExceptionHandler(value = &#123;MethodArgumentNotValidException.class&#125;)    public Response methodArgumentNotValidHandler(MethodArgumentNotValidException e) &#123;        log.info(e.getMessage(), e);        FieldError fieldError = e.getBindingResult().getFieldError();        return Response.failed(ResultCode.VALIDATE_FAILED, fieldError.getDefaultMessage());    &#125;    @ExceptionHandler(value = &#123;DuplicateKeyException.class&#125;)    public Response handleDuplicateKeyException(DuplicateKeyException e) &#123;        log.error(e.getMessage(), e);        return Response.failed(ResultCode.DUPLICATE_KEY);    &#125;    @ExceptionHandler(value = &#123;Exception.class&#125;)    public Response handle(Exception e) &#123;        log.error(e.getMessage(), e);        return Response.failed(ResultCode.FAILED);    &#125;&#125;\n\n业务统一异常import com.itran.fgoc.common.core.api.IErrorCode;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@NoArgsConstructor@AllArgsConstructorpublic class ApiException extends RuntimeException &#123;    /**     * 异常码     */    private IErrorCode errorCode;    /**     * 自定义错误描述     */    private String msg;    /**     * Instantiates a new Api exception.     *     * @param iErrorCode the error code     */    public ApiException(IErrorCode iErrorCode)&#123;        this.errorCode = iErrorCode;    &#125;&#125;\n\n统一异常码接口public interface IErrorCode &#123;    /**     * 异常编码     * @return     */    long getCode();    /**     * 异常信息     * @return     */    String getMessage();&#125;\n\n统一异常码实现类import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ResultCode implements IErrorCode &#123;    SUCCESS(200, &quot;操作成功&quot;),    FAILED(500, &quot;操作失败&quot;),    UNAUTHORIZED(401, &quot;暂未登录或token已经过期&quot;),    VALIDATE_FAILED(402, &quot;参数检验失败&quot;),    FORBIDDEN(403, &quot;没有相关权限&quot;),    LOGIN_FAILED(405, &quot;登录失败,帐号或密码错误&quot;),    LOGIN_CODE_TIMEOUT(405, &quot;登录失败,验证码已过期&quot;),    LOGIN_CODE_FAILED(405, &quot;登录失败,验证码输入错误&quot;),    DATA_IS_NULL(501, &quot;操作的数据异常&quot;),    REMOTE_CALL_FAILED(502, &quot;远程调用失败&quot;),    INSERT_ERROR(5000,&quot;插入数据失败！&quot;),    UPDATE_ERROR(5001,&quot;修改数据失败！&quot;),    DELETE_ERROR(5002,&quot;删除数据失败！&quot;),    DUPLICATE_KEY(5003,&quot;数据已存在！&quot;),    // 1001 用户相关    CODE_1001001(1001001, &quot;用户不存在&quot;),    CODE_1001002(1001002, &quot;用户名不能为空&quot;),    // 1002 权限相关    CODE_1002001(1002001, &quot;无操作权限&quot;),    ;    private long code;    private String message;&#125;\n\n\n\n\n\n自定义表单校验注解import com.itran.fgoc.common.core.var.NullVar;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Repeatable;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import javax.validation.Constraint;import javax.validation.Payload;/** * 校验字段是否是枚举中，null值不校验 * 校验顺序：intEnumValues -&gt; longEnumValues -&gt; stringEnumValues -&gt; enumClass */@Target(&#123;ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER, ElementType.TYPE_USE&#125;)@Retention(RetentionPolicy.RUNTIME)@Repeatable(Enum.List.class)@Documented@Constraint(    validatedBy = EnumValidator.class)public @interface Enum &#123;    String message() default &quot;枚举字段不正确&quot;;    Class&lt;?&gt; enumClass() default NullVar.class;    int[] intEnumValues() default &#123;&#125;;    long[] longEnumValues() default &#123;&#125;;    String[] stringEnumValues() default &#123;&#125;;    Class&lt;?&gt;[] groups() default &#123;&#125;;    Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;    @Target(&#123;ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER, ElementType.TYPE_USE&#125;)    @Retention(RetentionPolicy.RUNTIME)    @Documented    public @interface List &#123;        Enum[] value();    &#125;&#125;\n\n注解解析器import cn.hutool.core.util.ArrayUtil;import cn.hutool.core.util.ReflectUtil;import javax.validation.ConstraintValidator;import javax.validation.ConstraintValidatorContext;import java.util.Arrays;public class EnumValidator implements ConstraintValidator&lt;Enum, Object&gt; &#123;    private Object[] enumValues;    private int[] intEnumValues;    private long[] longEnumValues;    private String[] stringEnumValues;    public EnumValidator() &#123;    &#125;    @Override    public void initialize(Enum constraintAnnotation) &#123;        enumValues = ReflectUtil.getFieldsValue(constraintAnnotation.enumClass());        intEnumValues = constraintAnnotation.intEnumValues();        longEnumValues = constraintAnnotation.longEnumValues();        stringEnumValues = constraintAnnotation.stringEnumValues();    &#125;    public boolean isValid(Object object, ConstraintValidatorContext constraintValidatorContext) &#123;        if(object == null)&#123;            return true;        &#125;        if(!ArrayUtil.isEmpty(intEnumValues))&#123;            return ArrayUtil.contains(intEnumValues, (int)object);        &#125;        if(!ArrayUtil.isEmpty(longEnumValues))&#123;            return ArrayUtil.contains(longEnumValues, (long)object);        &#125;        if(!ArrayUtil.isEmpty(stringEnumValues))&#123;            return ArrayUtil.contains(stringEnumValues, (long)object);        &#125;        return Arrays.asList(enumValues).contains(object);    &#125;&#125;\n\n枚举示例import cn.hutool.core.map.MapUtil;import java.util.Map;public interface ContainerTypeVar&#123;    /**     * 轮廓     */    interface Contour &#123;        int RECTANGULAR_SOLID = 0;        int LOWER_LEFT_TRAPEZOID = 1;        int UPPER_LEFT_TRAPEZOID = 2;        int LOWER_TRAPEZOID = 3;        int UPPER_TRAPEZOID = 4;        Map&lt;Object, Object&gt; MSG = MapUtil.builder()                .put(RECTANGULAR_SOLID, &quot;长方体&quot;)                .put(LOWER_LEFT_TRAPEZOID, &quot;单切左下&quot;)                .put(UPPER_LEFT_TRAPEZOID, &quot;单切左上&quot;)                .put(LOWER_TRAPEZOID, &quot;双切下&quot;)                .put(UPPER_TRAPEZOID, &quot;双切上&quot;)                .build()                ;    &#125;&#125;\n\nNullVarpublic interface NullVar &#123;&#125;\n\n使用// 4种方式任选其一，优先级从上往下// 使用自定义int数组校验@Enum(intEnumValues = &#123;1,2&#125;, message = &quot;轮廓数据异常&quot;)private Integer contour;// 使用自定义long数组校验@Enum(longEnumValues = &#123;1,2&#125;, message = &quot;轮廓数据异常&quot;)private Integer contour;// 使用自定义string数组校验@Enum(stringEnumValues = &#123;&quot;1&quot;,&quot;2&quot;&#125;, message = &quot;轮廓数据异常&quot;)private Integer contour;// 使用枚举类校验@Enum(enumClass = ContainerTypeVar.Contour.class, message = &quot;轮廓数据异常&quot;)private Integer contour;\n\n默认表单校验\n\n\n限制\n说明\n\n\n\n@Null\n限制只能为null\n\n\n@NotNull\n限制必须不为null\n\n\n@AssertFalse\n限制必须为false\n\n\n@AssertTrue\n限制必须为true\n\n\n@DecimalMax(value)\n限制必须为一个不大于指定值的数字\n\n\n@DecimalMin(value)\n限制必须为一个不小于指定值的数字\n\n\n@Digits(integer,fraction)\n限制必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过fraction\n\n\n@Future\n限制必须是一个将来的日期\n\n\n@Max(value)\n限制必须为一个不大于指定值的数字\n\n\n@Min(value)\n限制必须为一个不小于指定值的数字\n\n\n@Past\n限制必须是一个过去的日期\n\n\n@Pattern(regexp)\n限制必须符合指定的正则表达式\n\n\n@Size(max,min)\n限制字符长度必须在min到max之间\n\n\n@Past\n验证注解的元素值（日期类型）比当前时间早\n\n\n@NotEmpty\n验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0）\n\n\n@NotBlank\n验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank只应用于字符串且在比较时会去除字符串的空格\n\n\n@Email\n验证注解的元素值是Email，也可以通过正则表达式和flag指定自定义的email格式\n\n\n参考链接https://www.cnblogs.com/cjsblog/p/8946768.htmlhttps://www.jianshu.com/p/8ea600893d87\n","categories":["java"],"tags":["springboot"]},{"title":"","url":"/about/index.html","content":"","categories":[],"tags":[]}]